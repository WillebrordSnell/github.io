<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.67" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="https://github.com/WillebrordSnell/keyan/dialog.html"><meta property="og:site_name" content=" "><meta property="og:title" content="ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†"><meta property="og:description" content="ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›† æœ¬æ–‡ä¸»è¦è®°å½•ä¸€ä¸‹è¿‘4å¹´(2019å¹´èµ·)å„é¡¶ä¼šé¡¶åˆŠæœ‰å…³dialogçš„paperåå­—ï¼Œä»¥ä¾¿åç»­video dialogå·¥ä½œçš„è°ƒç ”å’Œå±•å¼€ (æœ¬æ–‡æ¡£æœªç»è¿‡ä»»ä½•ç­›é€‰ï¼Œä»…é€šè¿‡å…³é”®è¯æœç´¢å¾—åˆ°paperåå­—) æ¨èäºŒçº§æ£€ç´¢å…³é”®è¯ï¼šhistory ã€ generaã€ visualã€ Supervisã€ videoç­‰ ECCV 2022 ECCV New Datasets and Models for Contextual Reasoning in Visual Dialog Video Dialog as Conversation About Objects Living in Space-Time"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2023-10-18T15:20:18.000Z"><meta property="article:author" content="Mr.R"><meta property="article:tag" content="å»ç å¤´æ•´ç‚¹è®ºæ–‡"><meta property="article:published_time" content="2023-09-19T00:00:00.000Z"><meta property="article:modified_time" content="2023-10-18T15:20:18.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†","image":[""],"datePublished":"2023-09-19T00:00:00.000Z","dateModified":"2023-10-18T15:20:18.000Z","author":[{"@type":"Person","name":"Mr.R","url":"https://github.com/WillebrordSnell"}]}</script><title>ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›† |  </title><meta name="description" content="ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›† æœ¬æ–‡ä¸»è¦è®°å½•ä¸€ä¸‹è¿‘4å¹´(2019å¹´èµ·)å„é¡¶ä¼šé¡¶åˆŠæœ‰å…³dialogçš„paperåå­—ï¼Œä»¥ä¾¿åç»­video dialogå·¥ä½œçš„è°ƒç ”å’Œå±•å¼€ (æœ¬æ–‡æ¡£æœªç»è¿‡ä»»ä½•ç­›é€‰ï¼Œä»…é€šè¿‡å…³é”®è¯æœç´¢å¾—åˆ°paperåå­—) æ¨èäºŒçº§æ£€ç´¢å…³é”®è¯ï¼šhistory ã€ generaã€ visualã€ Supervisã€ videoç­‰ ECCV 2022 ECCV New Datasets and Models for Contextual Reasoning in Visual Dialog Video Dialog as Conversation About Objects Living in Space-Time">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-7ba79056.css" as="style"><link rel="stylesheet" href="/assets/style-7ba79056.css">
    <link rel="modulepreload" href="/assets/app-69065092.js"><link rel="modulepreload" href="/assets/dialog.html-8936061b.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-c27b6911.js"><link rel="modulepreload" href="/assets/dialog.html-67f127ce.js"><link rel="prefetch" href="/assets/index.html-d9458bfe.js" as="script"><link rel="prefetch" href="/assets/intro.html-2e5e4af5.js" as="script"><link rel="prefetch" href="/assets/slides.html-fd5a002b.js" as="script"><link rel="prefetch" href="/assets/202309.html-74c2b100.js" as="script"><link rel="prefetch" href="/assets/202310.html-2458bec6.js" as="script"><link rel="prefetch" href="/assets/maoxuan.html-02808c56.js" as="script"><link rel="prefetch" href="/assets/index.html-bf1750b6.js" as="script"><link rel="prefetch" href="/assets/disable.html-28c49317.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-0f38acb2.js" as="script"><link rel="prefetch" href="/assets/markdown.html-d32d3131.js" as="script"><link rel="prefetch" href="/assets/page.html-d359f584.js" as="script"><link rel="prefetch" href="/assets/index.html-fd34dea5.js" as="script"><link rel="prefetch" href="/assets/video.html-b54bb940.js" as="script"><link rel="prefetch" href="/assets/index.html-a3a40393.js" as="script"><link rel="prefetch" href="/assets/index.html-3b3fc455.js" as="script"><link rel="prefetch" href="/assets/markdown01.html-8905e9eb.js" as="script"><link rel="prefetch" href="/assets/markdown02.html-054a564a.js" as="script"><link rel="prefetch" href="/assets/index.html-1c6f8d12.js" as="script"><link rel="prefetch" href="/assets/contrastiveLearning.html-9843d401.js" as="script"><link rel="prefetch" href="/assets/multiModal.html-c152230c.js" as="script"><link rel="prefetch" href="/assets/videoDialog.html-711d697d.js" as="script"><link rel="prefetch" href="/assets/videoRepresentation.html-7e948e5f.js" as="script"><link rel="prefetch" href="/assets/videoUnderstanding.html-8cede748.js" as="script"><link rel="prefetch" href="/assets/Bloodborne.html-ac9206cd.js" as="script"><link rel="prefetch" href="/assets/DeathStranding.html-d5380b1b.js" as="script"><link rel="prefetch" href="/assets/AVSD.html-bc3f49fd.js" as="script"><link rel="prefetch" href="/assets/DDP.html-d779b619.js" as="script"><link rel="prefetch" href="/assets/trick.html-bb31f35e.js" as="script"><link rel="prefetch" href="/assets/index.html-a202766c.js" as="script"><link rel="prefetch" href="/assets/manual01.html-0a8da7f1.js" as="script"><link rel="prefetch" href="/assets/manual02.html-d7e0e274.js" as="script"><link rel="prefetch" href="/assets/manual03.html-fc2fcb88.js" as="script"><link rel="prefetch" href="/assets/index.html-94ec1b0f.js" as="script"><link rel="prefetch" href="/assets/documentnotes01.html-3e3bf028.js" as="script"><link rel="prefetch" href="/assets/documentnotes02.html-b0ab3628.js" as="script"><link rel="prefetch" href="/assets/documentnotes03.html-dffc6ca6.js" as="script"><link rel="prefetch" href="/assets/documentnotes04.html-5c8e168f.js" as="script"><link rel="prefetch" href="/assets/documentnotes05.html-e6c9c3ad.js" as="script"><link rel="prefetch" href="/assets/documentnotes06.html-8351650a.js" as="script"><link rel="prefetch" href="/assets/documentnotes07.html-a1156cd2.js" as="script"><link rel="prefetch" href="/assets/documentnotes08.html-4dd750d8.js" as="script"><link rel="prefetch" href="/assets/documentnotes09.html-c3df51ca.js" as="script"><link rel="prefetch" href="/assets/documentnotes10.html-22d25bd9.js" as="script"><link rel="prefetch" href="/assets/documentnotes11.html-739f34bd.js" as="script"><link rel="prefetch" href="/assets/404.html-33087db7.js" as="script"><link rel="prefetch" href="/assets/index.html-f543ab52.js" as="script"><link rel="prefetch" href="/assets/index.html-edca5983.js" as="script"><link rel="prefetch" href="/assets/index.html-9e922b59.js" as="script"><link rel="prefetch" href="/assets/index.html-5d327b0f.js" as="script"><link rel="prefetch" href="/assets/index.html-64a9f81e.js" as="script"><link rel="prefetch" href="/assets/index.html-1eb7a45d.js" as="script"><link rel="prefetch" href="/assets/index.html-3b8e3fc4.js" as="script"><link rel="prefetch" href="/assets/index.html-c24f66de.js" as="script"><link rel="prefetch" href="/assets/index.html-b28248cf.js" as="script"><link rel="prefetch" href="/assets/index.html-11a8a3d5.js" as="script"><link rel="prefetch" href="/assets/index.html-5f4f46c8.js" as="script"><link rel="prefetch" href="/assets/index.html-3fa1430b.js" as="script"><link rel="prefetch" href="/assets/index.html-50095564.js" as="script"><link rel="prefetch" href="/assets/index.html-170b7dac.js" as="script"><link rel="prefetch" href="/assets/index.html-4450e009.js" as="script"><link rel="prefetch" href="/assets/index.html-cd5496ff.js" as="script"><link rel="prefetch" href="/assets/index.html-bf5da18c.js" as="script"><link rel="prefetch" href="/assets/index.html-789dc91d.js" as="script"><link rel="prefetch" href="/assets/index.html-598316da.js" as="script"><link rel="prefetch" href="/assets/index.html-deffa58c.js" as="script"><link rel="prefetch" href="/assets/index.html-cc90af66.js" as="script"><link rel="prefetch" href="/assets/index.html-78e1edef.js" as="script"><link rel="prefetch" href="/assets/index.html-95c6778e.js" as="script"><link rel="prefetch" href="/assets/index.html-ef15ab18.js" as="script"><link rel="prefetch" href="/assets/index.html-de15c52f.js" as="script"><link rel="prefetch" href="/assets/index.html-3ffa64a8.js" as="script"><link rel="prefetch" href="/assets/index.html-0c4ebc78.js" as="script"><link rel="prefetch" href="/assets/index.html-7c39f58a.js" as="script"><link rel="prefetch" href="/assets/index.html-dc0cfaa1.js" as="script"><link rel="prefetch" href="/assets/index.html-e6f556de.js" as="script"><link rel="prefetch" href="/assets/index.html-996c738c.js" as="script"><link rel="prefetch" href="/assets/index.html-946da1ee.js" as="script"><link rel="prefetch" href="/assets/index.html-30e4e921.js" as="script"><link rel="prefetch" href="/assets/index.html-e2a85053.js" as="script"><link rel="prefetch" href="/assets/index.html-41d7be7d.js" as="script"><link rel="prefetch" href="/assets/index.html-36154924.js" as="script"><link rel="prefetch" href="/assets/index.html-334a54b6.js" as="script"><link rel="prefetch" href="/assets/index.html-2ae1afae.js" as="script"><link rel="prefetch" href="/assets/index.html-0c3db965.js" as="script"><link rel="prefetch" href="/assets/index.html-6b1ed3d2.js" as="script"><link rel="prefetch" href="/assets/index.html-4e97df2f.js" as="script"><link rel="prefetch" href="/assets/index.html-f405b53b.js" as="script"><link rel="prefetch" href="/assets/intro.html-f33956a9.js" as="script"><link rel="prefetch" href="/assets/slides.html-c4cea489.js" as="script"><link rel="prefetch" href="/assets/202309.html-d2657dc1.js" as="script"><link rel="prefetch" href="/assets/202310.html-0391c605.js" as="script"><link rel="prefetch" href="/assets/maoxuan.html-45943cb3.js" as="script"><link rel="prefetch" href="/assets/index.html-a9ff0fa8.js" as="script"><link rel="prefetch" href="/assets/disable.html-e771a791.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-e979a465.js" as="script"><link rel="prefetch" href="/assets/markdown.html-2bf0a39f.js" as="script"><link rel="prefetch" href="/assets/page.html-3c278a4d.js" as="script"><link rel="prefetch" href="/assets/index.html-f534f767.js" as="script"><link rel="prefetch" href="/assets/video.html-48afa7df.js" as="script"><link rel="prefetch" href="/assets/index.html-d2669498.js" as="script"><link rel="prefetch" href="/assets/index.html-e23c2c15.js" as="script"><link rel="prefetch" href="/assets/markdown01.html-e6153832.js" as="script"><link rel="prefetch" href="/assets/markdown02.html-35613fa5.js" as="script"><link rel="prefetch" href="/assets/index.html-82df2a9e.js" as="script"><link rel="prefetch" href="/assets/contrastiveLearning.html-07e60719.js" as="script"><link rel="prefetch" href="/assets/multiModal.html-f4b62f59.js" as="script"><link rel="prefetch" href="/assets/videoDialog.html-7124fb13.js" as="script"><link rel="prefetch" href="/assets/videoRepresentation.html-6073b357.js" as="script"><link rel="prefetch" href="/assets/videoUnderstanding.html-c75ab87a.js" as="script"><link rel="prefetch" href="/assets/Bloodborne.html-086d12b5.js" as="script"><link rel="prefetch" href="/assets/DeathStranding.html-0d682b04.js" as="script"><link rel="prefetch" href="/assets/AVSD.html-68474ad1.js" as="script"><link rel="prefetch" href="/assets/DDP.html-664704d0.js" as="script"><link rel="prefetch" href="/assets/trick.html-52802859.js" as="script"><link rel="prefetch" href="/assets/index.html-9701d626.js" as="script"><link rel="prefetch" href="/assets/manual01.html-0fdb4786.js" as="script"><link rel="prefetch" href="/assets/manual02.html-039189fd.js" as="script"><link rel="prefetch" href="/assets/manual03.html-ea3013a1.js" as="script"><link rel="prefetch" href="/assets/index.html-8adb8545.js" as="script"><link rel="prefetch" href="/assets/documentnotes01.html-c72d4076.js" as="script"><link rel="prefetch" href="/assets/documentnotes02.html-bceb9121.js" as="script"><link rel="prefetch" href="/assets/documentnotes03.html-ca85b77f.js" as="script"><link rel="prefetch" href="/assets/documentnotes04.html-bef39389.js" as="script"><link rel="prefetch" href="/assets/documentnotes05.html-868bc913.js" as="script"><link rel="prefetch" href="/assets/documentnotes06.html-d19f9c7e.js" as="script"><link rel="prefetch" href="/assets/documentnotes07.html-3793c3c1.js" as="script"><link rel="prefetch" href="/assets/documentnotes08.html-c4a03b89.js" as="script"><link rel="prefetch" href="/assets/documentnotes09.html-f20bdf12.js" as="script"><link rel="prefetch" href="/assets/documentnotes10.html-6982487c.js" as="script"><link rel="prefetch" href="/assets/documentnotes11.html-1568e05f.js" as="script"><link rel="prefetch" href="/assets/404.html-4b12072b.js" as="script"><link rel="prefetch" href="/assets/index.html-d588b1c5.js" as="script"><link rel="prefetch" href="/assets/index.html-c60ca9e7.js" as="script"><link rel="prefetch" href="/assets/index.html-1396f605.js" as="script"><link rel="prefetch" href="/assets/index.html-148b335d.js" as="script"><link rel="prefetch" href="/assets/index.html-bb35d3d7.js" as="script"><link rel="prefetch" href="/assets/index.html-7809b718.js" as="script"><link rel="prefetch" href="/assets/index.html-4d99fd73.js" as="script"><link rel="prefetch" href="/assets/index.html-a3bbc3b6.js" as="script"><link rel="prefetch" href="/assets/index.html-a613be88.js" as="script"><link rel="prefetch" href="/assets/index.html-06aa8597.js" as="script"><link rel="prefetch" href="/assets/index.html-ac61f066.js" as="script"><link rel="prefetch" href="/assets/index.html-c7f770cd.js" as="script"><link rel="prefetch" href="/assets/index.html-44991978.js" as="script"><link rel="prefetch" href="/assets/index.html-3f4e2390.js" as="script"><link rel="prefetch" href="/assets/index.html-b1cb4a47.js" as="script"><link rel="prefetch" href="/assets/index.html-4fc3831c.js" as="script"><link rel="prefetch" href="/assets/index.html-fec6da0a.js" as="script"><link rel="prefetch" href="/assets/index.html-5a28c50e.js" as="script"><link rel="prefetch" href="/assets/index.html-6a412710.js" as="script"><link rel="prefetch" href="/assets/index.html-895c8a23.js" as="script"><link rel="prefetch" href="/assets/index.html-747b07f1.js" as="script"><link rel="prefetch" href="/assets/index.html-2926bd0d.js" as="script"><link rel="prefetch" href="/assets/index.html-fdc959a4.js" as="script"><link rel="prefetch" href="/assets/index.html-619ab7d6.js" as="script"><link rel="prefetch" href="/assets/index.html-1b303635.js" as="script"><link rel="prefetch" href="/assets/index.html-2e51ab60.js" as="script"><link rel="prefetch" href="/assets/index.html-271f8410.js" as="script"><link rel="prefetch" href="/assets/index.html-6b94187e.js" as="script"><link rel="prefetch" href="/assets/index.html-2229390a.js" as="script"><link rel="prefetch" href="/assets/index.html-bf151ad3.js" as="script"><link rel="prefetch" href="/assets/index.html-c3f24fb7.js" as="script"><link rel="prefetch" href="/assets/index.html-304cfab6.js" as="script"><link rel="prefetch" href="/assets/index.html-3823a98b.js" as="script"><link rel="prefetch" href="/assets/index.html-96fa35fa.js" as="script"><link rel="prefetch" href="/assets/index.html-3cc1206a.js" as="script"><link rel="prefetch" href="/assets/index.html-66de2602.js" as="script"><link rel="prefetch" href="/assets/index.html-e8a239f8.js" as="script"><link rel="prefetch" href="/assets/index.html-7e1f7396.js" as="script"><link rel="prefetch" href="/assets/index.html-94df3049.js" as="script"><link rel="prefetch" href="/assets/index.html-00cfbd53.js" as="script"><link rel="prefetch" href="/assets/index.html-d4a0acd9.js" as="script"><link rel="prefetch" href="/assets/auto-fe80bb03.js" as="script"><link rel="prefetch" href="/assets/index-2bf332f6.js" as="script"><link rel="prefetch" href="/assets/flowchart-c441f34d.js" as="script"><link rel="prefetch" href="/assets/mermaid.core-36bfb00a.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-75b11b9d.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-9d5bc2ce.js" as="script"><link rel="prefetch" href="/assets/math.esm-70a288c8.js" as="script"><link rel="prefetch" href="/assets/notes.esm-a106bb2c.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-1a4c3ae7.js" as="script"><link rel="prefetch" href="/assets/search.esm-7e6792e2.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-b83b91d0.js" as="script"><link rel="prefetch" href="/assets/VuePlayground-8cf4125f.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-5762295a.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">è·³è‡³ä¸»è¦å…§å®¹</a><!--]--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/"><img class="vp-nav-logo" src="/logo.svg" alt=" "><!----><span class="vp-site-name hide-in-pad"> </span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="ğŸ”§ å·¥å…·"><span class="title"><!---->ğŸ”§ å·¥å…·</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>æ–‡æ¡£</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a aria-label="Markdown" class="vp-link nav-link nav-link" href="/Tools/MarkDown.html"><!---->Markdown<!----></a></li><li class="dropdown-subitem"><a aria-label="èµ„æºæ•´åˆ" class="vp-link nav-link nav-link" href="/Tools/Resource.html"><!---->èµ„æºæ•´åˆ<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>å·¥å…·</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a aria-label="Git" class="vp-link nav-link nav-link" href="/Tools/Git.html"><!---->Git<!----></a></li></ul></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="  ğŸ“‘ ç å¤´"><span class="title"><!---->  ğŸ“‘ ç å¤´</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="è§†é¢‘ç†è§£" class="vp-link nav-link nav-link" href="/keyan/videoUnderstanding/videoUnderstanding.html"><!---->è§†é¢‘ç†è§£<!----></a></li><li class="dropdown-item"><a aria-label="è§†é¢‘è¡¨å¾" class="vp-link nav-link nav-link" href="/keyan/videoRepresentation/videoRepresentation.html"><!---->è§†é¢‘è¡¨å¾<!----></a></li><li class="dropdown-item"><a aria-label="è§†é¢‘å¯¹è¯" class="vp-link nav-link nav-link" href="/keyan/videoDialog/videoDialog.html"><!---->è§†é¢‘å¯¹è¯<!----></a></li><li class="dropdown-item"><a aria-label="å¯¹æ¯”å­¦ä¹ " class="vp-link nav-link nav-link" href="/keyan/contrastiveLearning/contrastiveLearning.html"><!---->å¯¹æ¯”å­¦ä¹ <!----></a></li><li class="dropdown-item"><a aria-label="å¤šæ¨¡æ€" class="vp-link nav-link nav-link" href="/keyan/multiModal/multiModal.html"><!---->å¤šæ¨¡æ€<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="  ğŸ§« ç‚‰"><span class="title"><!---->  ğŸ§« ç‚‰</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="å•æœºå¤šå¡DDP" class="vp-link nav-link nav-link" href="/train/DDP/DDP.html"><!---->å•æœºå¤šå¡DDP<!----></a></li><li class="dropdown-item"><a aria-label="AVSD" class="vp-link nav-link nav-link" href="/train/AVSD/AVSD.html"><!---->AVSD<!----></a></li><li class="dropdown-item"><a aria-label="å¥‡æ·«æŠ€å·§" class="vp-link nav-link nav-link" href="/train/trick/trick.html"><!---->å¥‡æ·«æŠ€å·§<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="  ğŸ“– é“å¿ƒ"><span class="title"><!---->  ğŸ“– é“å¿ƒ</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="2023å¹´9æœˆ" class="vp-link nav-link nav-link" href="/book/202309.html"><!---->2023å¹´9æœˆ<!----></a></li><li class="dropdown-item"><a aria-label="2023å¹´10æœˆ" class="vp-link nav-link nav-link" href="/book/202310.html"><!---->2023å¹´10æœˆ<!----></a></li><li class="dropdown-item"><a aria-label="æ¯›æ³½ä¸œé€‰é›†" class="vp-link nav-link nav-link" href="/book/maoxuan.html"><!---->æ¯›æ³½ä¸œé€‰é›†<!----></a></li></ul></button></div></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><!--[--><a aria-label="è§†é¢‘ç†è§£ç»¼è¿°æ€§è´¨çš„è®°å½•" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/videoUnderstanding/videoUnderstanding.html"><!---->è§†é¢‘ç†è§£ç»¼è¿°æ€§è´¨çš„è®°å½•<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="å…³äºè§†é¢‘ç†è§£çš„è®ºæ–‡æ”¶é›†(è¾ƒæ–°)" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/videoRepresentation/videoRepresentation.html"><!---->å…³äºè§†é¢‘ç†è§£çš„è®ºæ–‡æ”¶é›†(è¾ƒæ–°)<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="è§†é¢‘å¯¹è¯æ–¹å‘å¤§è®ºæ–‡æ€§è´¨çš„è®°å½•" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/videoDialog/videoDialog.html"><!---->è§†é¢‘å¯¹è¯æ–¹å‘å¤§è®ºæ–‡æ€§è´¨çš„è®°å½•<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="å¯¹æ¯”å­¦ä¹ ç»¼è¿°æ€§è´¨çš„è®°å½•" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/contrastiveLearning/contrastiveLearning.html"><!---->å¯¹æ¯”å­¦ä¹ ç»¼è¿°æ€§è´¨çš„è®°å½•<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="å¤šæ¨¡æ€æ–¹å‘ç»¼è¿°æ€§è´¨çš„è®°å½•" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/multiModal/multiModal.html"><!---->å¤šæ¨¡æ€æ–¹å‘ç»¼è¿°æ€§è´¨çš„è®°å½•<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†</h1><div class="page-info"><span class="page-author-info" aria-label="ä½œè€…ğŸ–Š" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/WillebrordSnell" target="_blank" rel="noopener noreferrer">Mr.R</a></span><span property="author" content="Mr.R"></span></span><!----><span class="page-date-info" aria-label="å†™ä½œæ—¥æœŸğŸ“…" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-09-19T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="é˜…è¯»æ—¶é—´âŒ›" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>å¤§çº¦ 20 åˆ†é’Ÿ</span><meta property="timeRequired" content="PT20M"></span><span class="page-category-info" aria-label="åˆ†ç±»ğŸŒˆ" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category3 clickable" role="navigation">ç§‘ç ”</span><!--]--><meta property="articleSection" content="ç§‘ç ”"></span><span class="page-tag-info" aria-label="æ ‡ç­¾ğŸ·" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag1 clickable" role="navigation">å»ç å¤´æ•´ç‚¹è®ºæ–‡</span><!--]--><meta property="keywords" content="å»ç å¤´æ•´ç‚¹è®ºæ–‡"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">æ­¤é¡µå†…å®¹<button type="button" class="print-button" title="æ‰“å°"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#eccv">ECCV</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2022-eccv">2022 ECCV</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2020-eccv">2020 ECCV</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#iccv">ICCV</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2021-iccv">2021 ICCV</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2019-iccv">2019 ICCV</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#cvpr">CVPR</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2023-cvpr">2023 CVPR</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2022-cvpr">2022 CVPR</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2021-cvpr">2021 CVPR</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2020-cvpr">2020 CVPR</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2019-cvpr">2019 CVPR</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#aaai">AAAI</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2023-aaai">2023 AAAI</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2022-aaai">2022 AAAI</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2021-aaai">2021 AAAI</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2020-aaai">2020 AAAI</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2019-aaai">2019 AAAI</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#emnlp">EMNLP</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2023-emnlp">2023 EMNLP</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2022-emnlp">2022 EMNLP</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2021-emnlp">2021 EMNLP</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2020-emnlp">2020 EMNLP</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2019-emnlp">2019 EMNLP</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#acl">ACL</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2023-acl">2023 ACL</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2022-acl">2022 ACL</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2021-acl">2021 ACL</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2020-acl">2020 ACL</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2019-acl">2019 ACL</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><h1 id="ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†" tabindex="-1"><a class="header-anchor" href="#ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†" aria-hidden="true">#</a> ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†</h1><p>æœ¬æ–‡ä¸»è¦è®°å½•ä¸€ä¸‹è¿‘4å¹´(2019å¹´èµ·)å„é¡¶ä¼šé¡¶åˆŠæœ‰å…³dialogçš„paperåå­—ï¼Œä»¥ä¾¿åç»­video dialogå·¥ä½œçš„è°ƒç ”å’Œå±•å¼€<br> (æœ¬æ–‡æ¡£æœªç»è¿‡ä»»ä½•ç­›é€‰ï¼Œä»…é€šè¿‡å…³é”®è¯æœç´¢å¾—åˆ°paperåå­—)<br> æ¨èäºŒçº§æ£€ç´¢å…³é”®è¯ï¼šhistory ã€ generaã€ visualã€ Supervisã€ videoç­‰</p><h2 id="eccv" tabindex="-1"><a class="header-anchor" href="#eccv" aria-hidden="true">#</a> ECCV</h2><h3 id="_2022-eccv" tabindex="-1"><a class="header-anchor" href="#_2022-eccv" aria-hidden="true">#</a> 2022 ECCV</h3><p>New Datasets and Models for Contextual Reasoning in Visual Dialog<br> Video Dialog as Conversation About Objects Living in Space-Time</p><h3 id="_2020-eccv" tabindex="-1"><a class="header-anchor" href="#_2020-eccv" aria-hidden="true">#</a> 2020 ECCV</h3><p>Efficient Attention Mechanism for Visual Dialog that Can Handle All the Interactions Between Multiple Inputs<br> Describing Unseen Videos via Multi-modal Cooperative Dialog Agents<br> Large-Scale Pretraining for Visual Dialog: A Simple State-of-the-Art Baseline<br> Guessing State Tracking for Visual Dialogue</p><h2 id="iccv" tabindex="-1"><a class="header-anchor" href="#iccv" aria-hidden="true">#</a> ICCV</h2><h3 id="_2021-iccv" tabindex="-1"><a class="header-anchor" href="#_2021-iccv" aria-hidden="true">#</a> 2021 ICCV</h3><p>Self-Motivated Communication Agent for Real-World Vision-Dialog Navigation<br> Unified Questioner Transformer for Descriptive Question Generation in Goal-Oriented Visual Dialogue<br> On the hidden treasure of dialog in video question answering<br> Talk-to-Edit: Fine-Grained Facial Editing via Dialog</p><h3 id="_2019-iccv" tabindex="-1"><a class="header-anchor" href="#_2019-iccv" aria-hidden="true">#</a> 2019 ICCV</h3><p>Making History Matter: History-Advantage Sequence Training for Visual Dialog</p><h2 id="cvpr" tabindex="-1"><a class="header-anchor" href="#cvpr" aria-hidden="true">#</a> CVPR</h2><h3 id="_2023-cvpr" tabindex="-1"><a class="header-anchor" href="#_2023-cvpr" aria-hidden="true">#</a> 2023 CVPR</h3><p>The Dialog Must Go On: Improving Visual Dialog via Generative Self-Training</p><h3 id="_2022-cvpr" tabindex="-1"><a class="header-anchor" href="#_2022-cvpr" aria-hidden="true">#</a> 2022 CVPR</h3><p>UTC: A Unified Transformer with Inter-Task Contrastive Learning for Visual Dialog</p><h3 id="_2021-cvpr" tabindex="-1"><a class="header-anchor" href="#_2021-cvpr" aria-hidden="true">#</a> 2021 CVPR</h3><p>Learning Better Visual Dialog Agents With Pretrained Visual-Linguistic Representation</p><h3 id="_2020-cvpr" tabindex="-1"><a class="header-anchor" href="#_2020-cvpr" aria-hidden="true">#</a> 2020 CVPR</h3><p>Iterative Context-Aware Graph Inference for Visual Dialog<br> Vision-Dialog Navigation by Exploring Cross-Modal Memory<br> Two Causal Principles for Improving Visual Dialog</p><h3 id="_2019-cvpr" tabindex="-1"><a class="header-anchor" href="#_2019-cvpr" aria-hidden="true">#</a> 2019 CVPR</h3><p>Reasoning Visual Dialogs With Structural and Partial Observations<br> Recursive Visual Attention in Visual Dialog<br> Audio Visual Scene-Aware Dialog<br> Image-Question-Answer Synergistic Network for Visual Dialog<br> A Simple Baseline for Audio-Visual Scene-Aware Dialog</p><h2 id="aaai" tabindex="-1"><a class="header-anchor" href="#aaai" aria-hidden="true">#</a> AAAI</h2><h3 id="_2023-aaai" tabindex="-1"><a class="header-anchor" href="#_2023-aaai" aria-hidden="true">#</a> 2023 AAAI</h3><p>Learning to Memorize Entailment and Discourse Relations for Persona-Consistent Dialogues<br> Learning towards Selective Data Augmentation for Dialogue Generation<br> Learning to Imagine: Distillation-Based Interactive Context Exploitation for Dialogue State Tracking<br> Personalized Dialogue Generation with Persona-Adaptive Attention<br> Explaining (Sarcastic) Utterances to Enhance Affect Understanding in Multimodal Dialogues<br> Mitigating Negative Style Transfer in Hybrid Dialogue System<br> Heterogeneous-Branch Collaborative Learning for Dialogue Generation<br> Learning to Know Myself: A Coarse-to-Fine Persona-Aware Training Framework for Personalized Dialogue Generation<br> A Disentangled-Attention Based Framework with Persona-Aware Prompt Learning for Dialogue Generation<br> Towards Credible Human Evaluation of Open-Domain Dialog Systems Using Interactive Setup<br> Towards Complex Scenarios: Building End-to-End Task-Oriented Dialogue System across Multiple Knowledge Bases<br> Towards Diverse, Relevant and Coherent Open-Domain Dialogue Generation via Hybrid Latent Variables<br> Taming Continuous Posteriors for Latent Variational Dialogue Policies<br> Dialogue Rewriting via Skeleton-Guided Generation<br> Dialogue State Distillation Network with Inter-slot Contrastive Learning for Dialogue State Tracking<br> Balanced Meta Learning and Diverse Sampling for Lifelong Task-Oriented Dialogue Systems<br> On the Calibration and Uncertainty with PÃ³lya-Gamma Augmentation for Dialog Retrieval Models<br> Multi-Action Dialog Policy Learning from Logged User Feedback<br> KPT: Keyword-Guided Pre-training for Grounded Dialog Generation<br> Help Me Heal: A Reinforced Polite and Empathetic Mental Health and Legal Counseling Dialogue System for Crime Victims<br> Improving Dialogue Intent Classification with a Knowledge-Enhanced Multifactor Graph Model (Student Abstract)<br> Class Incremental Learning for Task-Oriented Dialogue System with Contrastive Distillation on Internal Representations (Student Abstract)</p><h3 id="_2022-aaai" tabindex="-1"><a class="header-anchor" href="#_2022-aaai" aria-hidden="true">#</a> 2022 AAAI</h3><p>ALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with Semi-supervised Learning and Explicit Policy Injection<br> Dual Task Framework for Improving Persona-Grounded Dialogue Dataset<br> SGD-X: A Benchmark for Robust Generalization in Schema-Guided Dialogue Systems<br> Knowledge Bridging for Empathetic Dialogue Generation<br> Contrast and Generation Make BART a Good Dialogue Emotion Recognizer<br> A Semi-supervised Learning Approach with Two Teachers to Improve Breakdown Identification in Dialogues<br> Semantic Parsing in Task-Oriented Dialog with Recursive Insertion-Based Encoder<br> CINS: Comprehensive Instruction for Few-Shot Learning in Task-Oriented Dialog Systems<br> GraphMemDialog: Optimizing End-to-End Task-Oriented Dialog Systems Using Graph Memory Networks<br> ValueNet: A New Dataset for Human Value Driven Dialogue System<br> Fusing Task-Oriented and Open-Domain Dialogues in Conversational Agents<br> MDD-Eval: Self-Training on Augmented Data for Multi-Domain Dialogue Evaluation<br> Efficient Dialog Policy Learning by Reasoning with Contextual Knowledge<br> DialogLM: Pre-trained Model for Long Dialogue Understanding and Summarization<br> Multi-Dimension Attention for Multi-Turn Dialog Generation (Student Abstract)<br> Building Goal-Oriented Dialogue Systems with Situated Visual Context</p><h3 id="_2021-aaai" tabindex="-1"><a class="header-anchor" href="#_2021-aaai" aria-hidden="true">#</a> 2021 AAAI</h3><p>Dynamic Graph Representation Learning for Video Dialog via Multi-Modal Shuffled Transformers<br> Structured Co-reference Graph Attention for Video-grounded Dialogue<br> Reasoning in Dialog: Improving Response Generation by Context Reading Comprehension<br> MultiTalk: A Highly-Branching Dialog Testbed for Diverse Conversations<br> Multi-View Feature Representation for Dialogue Generation with Bidirectional Distillation<br> DialogBERT: Discourse-Aware Response Generation via Learning to Recover and Rank Utterances<br> DDRel: A New Dataset for Interpersonal Relation Classification in Dyadic Dialogues<br> Interpretable NLG for Task-oriented Dialogue Systems with Heterogeneous Rendering Machines<br> Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation<br> Converse, Focus and Guess - Towards Multi-Document Driven Dialogue<br> Filling the Gap of Utterance-aware and Speaker-aware Representation for Multi-turn Dialogue<br> Dialog Policy Learning for Joint Clarification and Active Learning Queries<br> A Student-Teacher Architecture for Dialog Domain Adaptation Under the Meta-Learning Setting<br> Exploring Auxiliary Reasoning Tasks for Task-oriented Dialog Systems with Meta Cooperative Learning<br> Co-GAT: A Co-Interactive Graph Attention Network for Joint Dialog Act Recognition and Sentiment Classification<br> DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition<br> Unsupervised Learning of Deterministic Dialogue Structure with Edge-Enhanced Graph Auto-Encoder<br> NaturalConv: A Chinese Dialogue Dataset Towards Multi-turn Topic-driven Conversation<br> Learning an Effective Context-Response Matching Model with Self-Supervised Tasks for Retrieval-based Dialogues<br> Topic-Aware Multi-turn Dialogue Modeling<br> UBAR: Towards Fully End-to-End Task-Oriented Dialog System with GPT-2<br> Open Domain Dialogue Generation with Latent Images<br> Unsupervised Abstractive Dialogue Summarization for Tete-a-Tetes<br> Automatic Curriculum Learning With Over-repetition Penalty for Dialogue Policy Learning<br> Stylized Dialogue Response Generation Using Stylized Unpaired Texts<br> Topic-Oriented Spoken Dialogue Summarization for Customer Service with Saliency-Aware Topic Modeling<br> Lifelong and Continual Learning Dialogue Systems: Learning during Conversation<br> Empowering Conversational AI is a Trip to Mars: Progress and Future of Open Domain Human-Computer Dialogues<br> Knowledge-aware Dialogue Generation with Hybrid Attention (Student Abstract)<br> Bootstrapping Dialog Models from Human to Human Conversation Logs<br> Dialog Router: Automated Dialog Transition via Multi-Task Learning<br> Integrating Pre-trained Model into Rule-based Dialogue Management</p><h3 id="_2020-aaai" tabindex="-1"><a class="header-anchor" href="#_2020-aaai" aria-hidden="true">#</a> 2020 AAAI</h3><p>Towards Hands-Free Visual Dialog Interactive Recommendation<br> Modeling Dialogues with Hashcode Representations: A Nonparametric Approach<br> Learning from Easy to Complex: Adaptive Multi-Curricula Learning for Neural Dialogue Generation<br> DMRM: A Dual-Channel Multi-Hop Reasoning Model for Visual Dialog<br> Schema-Guided Multi-Domain Dialogue State Tracking with Graph Attention Neural Networks<br> Guiding Attention in Sequence-to-Sequence Models for Dialogue Act Prediction<br> Likelihood Ratios and Generative Classifiers for Unsupervised Out-of-Domain Detection in Task Oriented Dialog<br> Predictive Engagement: An Efficient Metric for Automatic Evaluation of Open-Domain Dialogue Systems<br> MALA: Cross-Domain Dialogue Generation with Action Learning<br> Bayes-Adaptive Monte-Carlo Planning and Learning for Goal-Oriented Dialogues<br> Modality-Balanced Models for Visual Dialogue<br> MA-DST: Multi-Attention-Based Scalable Dialog State Tracking<br> ALOHA: Artificial Learning of Human Attributes for Dialogue Agents<br> End-to-End Trainable Non-Collaborative Dialog System<br> MOSS: End-to-End Dialog System Framework with Modular Supervision<br> Attention-Informed Mixed-Language Training for Zero-Shot Cross-Lingual Task-Oriented Dialogue Systems<br> MTSS: Learn from Multiple Domain Teachers and Become a Multi-Domain Dialogue Expert<br> DCR-Net: A Deep Co-Interactive Relation Network for Joint Dialog Act Recognition and Sentiment Classification<br> Entrainment2Vec: Embedding Entrainment for Multi-Party Dialogues<br> Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided Dialogue Dataset<br> Hierarchical Reinforcement Learning for Open-Domain Dialog<br> Generating Persona Consistent Dialogues by Exploiting Natural Language Inference<br> History-Adaption Knowledge Incorporation Mechanism for Multi-Turn Dialogue System<br> Improving Knowledge-Aware Dialogue Generation via Knowledge Base Question Answering<br> Sentiment Classification in Customer Service Dialogue with Topic-Aware Multi-Task Learning<br> Masking Orchestration: Multi-Task Pretraining for Multi-Role Dialogue Representation Learning<br> Dialog State Tracking with Reinforced Data Augmentation<br> Filling Conversation Ellipsis for Better Social Dialog Understanding<br> Task-Oriented Dialog Systems That Consider Multiple Appropriate Responses under the Same Context<br> A Pre-Training Based Personalized Dialogue Generation Model with Persona-Sparse Data<br> DualVD: An Adaptive Dual Encoding Model for Deep Visual Understanding in Visual Dialogue<br> Visual Dialogue State Tracking for Question Generation<br> Multi-Speaker Video Dialog with Frame-Level Temporal Localization<br> Back to the Future for Dialogue Research<br> Doc2Dial: A Framework for Dialogue Composition Grounded in Documents<br> Automatic Text-Based Personality Recognition on Monologues and Multiparty Dialogues Using Attentive Networks and Contextual Embeddings (Student Abstract)<br> Topic Enhanced Controllable CVAE for Dialogue Generation (Student Abstract)<br> Breakdown Detection in Negotiation Dialogues (Student Abstract)</p><h3 id="_2019-aaai" tabindex="-1"><a class="header-anchor" href="#_2019-aaai" aria-hidden="true">#</a> 2019 AAAI</h3><p>Goal-Oriented Dialogue Policy Learning from Failures<br> Re-Evaluating ADEM: A Deeper Look at Scoring Dialogue Responses<br> Dialogue Generation: From Imitation Learning to Inverse Reinforcement Learning<br> Learning Personalized End-to-End Goal-Oriented Dialog<br> DialogueRNN: An Attentive RNN for Emotion Detection in Conversations<br> A Deep Sequential Model for Discourse Parsing on Multi-Party Dialogues<br> Switch-Based Active Deep Dyna-Q: Efficient Adaptive Planning for Task-Completion Dialogue Policy Learning<br> End-to-End Knowledge-Routed Relational Dialogue System for Automatic Diagnosis<br> MAi: An Intelligent Model Acquisition Interface for Interactive Specification of Dialogue Agents<br> Reinforcement Learning for Improved Low Resource Dialogue Generation</p><h2 id="emnlp" tabindex="-1"><a class="header-anchor" href="#emnlp" aria-hidden="true">#</a> EMNLP</h2><h3 id="_2023-emnlp" tabindex="-1"><a class="header-anchor" href="#_2023-emnlp" aria-hidden="true">#</a> 2023 EMNLP</h3><h3 id="_2022-emnlp" tabindex="-1"><a class="header-anchor" href="#_2022-emnlp" aria-hidden="true">#</a> 2022 EMNLP</h3><p>BotSIM: An End-to-End Bot Simulation Framework for Commercial Task-Oriented Dialog Systems<br> InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning<br> Correctable-DST: Mitigating Historical Context Mismatch between Training and Inference for Improved Dialogue State Tracking<br> Curriculum Prompt Learning with Self-Training for Abstractive Dialogue Summarization<br> MetaASSIST: Robust Dialogue State Tracking with Meta Learning<br> Counterfactual Data Augmentation via Perspective Transition for Open-Domain Dialogues<br> There Is No Standard Answer: Knowledge-Grounded Dialogue Generation with Adversarial Activated Multi-Reference Learning<br> D4: a Chinese Dialogue Dataset for Depression-Diagnosis-Oriented Chat<br> Exploiting domain-slot related keywords description for Few-Shot Cross-Domain Dialogue State Tracking<br> Navigating Connected Memories with a Task-oriented Dialog System<br> Back to the Future: Bidirectional Information Decoupling Network for Multi-turn Dialogue Modeling<br> Improving Multi-turn Emotional Support Dialogue Generation with Lookahead Strategy Planning<br> Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems<br> FineD-Eval: Fine-grained Automatic Dialogue-Level Evaluation<br> ProsocialDialog: A Prosocial Backbone for Conversational Agents<br> CGoDial: A Large-Scale Benchmark for Chinese Goal-oriented Dialog Evaluation<br> Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue<br> A Speaker-Aware Co-Attention Framework for Medical Dialogue Information Extraction<br> Analyzing and Evaluating Faithfulness in Dialogue Summarization<br> STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension<br> BotsTalk: Machine-sourced Framework for Automatic Curation of Large-scale Multi-skill Dialogue Datasets<br> Q-TOD: A Query-driven Task-oriented Dialogue System<br> Dial2vec: Self-Guided Contrastive Learning of Unsupervised Dialogue Embeddings<br> Extending Phrase Grounding with Pronouns in Visual Dialogues<br> ClidSum: A Benchmark Dataset for Cross-Lingual Dialogue Summarization<br> Human-Machine Collaboration Approaches to Build a Dialogue Dataset for Hate Speech Countering<br> Don&#39;t Copy the Teacher: Data and Model Challenges in Embodied Dialogue<br> Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence<br> Towards Efficient Dialogue Pre-training with Transferable and Interpretable Latent Structure<br> Reflect, Not Reflex: Inference-Based Common Ground Improves Dialogue Response Quality<br> FlowEval: A Consensus-Based Dialogue Evaluation Framework Using Segment Act Flows<br> Pneg: Prompt-based Negative Response Generation for Dialogue Response Selection Task<br> Structural Constraints and Natural Language Inference for End-to-End Flowchart Grounded Dialog Response Generation<br> FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue<br> IMâŒƒ2: an Interpretable and Multi-category Integrated Metric Framework for Automatic Dialogue Evaluation<br> Prompt Conditioned VAE: Enhancing Generative Replay for Lifelong Learning in Task-Oriented Dialogue<br> End-to-End Neural Discourse Deixis Resolution in Dialogue<br> CDialog: A Multi-turn Covid-19 Conversation Dataset for Entity-Aware Dialog Generation<br> Injecting Domain Knowledge in Language Models for Task-oriented Dialogue Systems<br> JDDC 2.1: A Multimodal Chinese Dialogue Dataset with Joint Tasks of Query Rewriting, Response Generation, Discourse Parsing, and Summarization<br> DialogConv: A Lightweight Fully Convolutional Network for Multi-view Response Selection</p><h3 id="_2021-emnlp" tabindex="-1"><a class="header-anchor" href="#_2021-emnlp" aria-hidden="true">#</a> 2021 EMNLP</h3><p>Athena 2.0: Contextualized Dialogue Management for an Alexa Prize SocialBot<br> Towards Making the Most of Dialogue Characteristics for Neural Chat Translation<br> Low-Resource Dialogue Summarization with Domain-Agnostic Multi-Source Pretraining<br> Controllable Neural Dialogue Summarization with Personal Named Entity Planning<br> GOLD: Improving Out-of-Scope Detection in Dialogues using Data Augmentation<br> Graph Based Network with Contextualized Representations of Turns in Dialogue<br> Automatically Exposing Problems with Neural Dialog Models<br> MindCraft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks<br> Cross-lingual Intermediate Fine-tuning improves Dialogue State Tracking<br> We&#39;ve had this conversation before: A Novel Approach to Measuring Dialog Similarity<br> CR-Walker: Tree-Structured Graph Reasoning and Dialog Acts for Conversational Recommendation<br> DIALKI: Knowledge Identification in Conversational Systems through Dialogue-Document Contextualization<br> Self-training Improves Pre-training for Few-shot Learning in Task-oriented Dialog Systems<br> Contextual Rephrase Detection for Reducing Friction in Dialogue Systems<br> Reference-Centric Models for Grounded Collaborative Dialogue<br> Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path Grounding<br> Thinking Clearly, Talking Fast: Concept-Guided Non-Autoregressive Generation for Open-Domain Dialogue Systems<br> Generation and Extraction Combined Dialogue State Tracking with Hierarchical Ontology Integration<br> CoLV: A Collaborative Latent Variable Model for Knowledge-Grounded Dialogue Generation<br> A Three-Stage Learning Framework for Low-Resource Knowledge-Grounded Dialogue Generation<br> Intention Reasoning Network for Multi-Domain End-to-end Task-Oriented Dialogue<br> More is Better: Enhancing Open-Domain Dialogue Generation via Multi-Source Heterogeneous Knowledge<br> Domain-Lifelong Learning for Dialogue State Tracking via Knowledge Preservation Networks<br> Different Strokes for Different Folks: Investigating Appropriate Further Pre-training Approaches for Diverse Dialogue Tasks<br> Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation<br> Don&#39;t be Contradicted with Anything! CI-ToD: Towards Benchmarking Consistency for Task-oriented Dialogue System<br> Transferable Persona-Grounded Dialogues via Grounded Minimal Edits<br> DialogueCSE: Dialogue-based Contrastive Learning of Sentence Embeddings<br> Adaptive Bridge between Training and Inference for Dialogue Generation<br> Smoothing Dialogue States for Open Conversational Machine Reading<br> Exophoric Pronoun Resolution in Dialogues with Topic Regularization<br> Contextualize Knowledge Bases with Transformer for End-to-end Task-Oriented Dialogue Systems<br> Efficient Dialogue Complementary Policy Learning via Deep Q-network Policy and Episodic Memory Policy<br> End-to-End Learning of Flowchart Grounded Task-Oriented Dialogs<br> CSDS: A Fine-Grained Chinese Dataset for Customer Service Dialogue Summarization<br> Building and Evaluating Open-Domain Dialogue Corpora with Clarifying Questions<br> Region under Discussion for visual dialog<br> Just Say No: Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts<br> Multi-Modal Open-Domain Dialogue<br> Zero-Shot Dialogue Disentanglement by Self-Supervised Entangled Response Selection<br> SIMMC 2.0: A Task-oriented Dialog Dataset for Immersive Multimodal Conversations<br> RAST: Domain-Robust Dialogue Rewriting as Sequence Tagging<br> MRF-Chat: Improving Dialogue with Markov Random Fields<br> Dialogue State Tracking with a Language Model using Schema-Driven Prompting<br> MultiDoc2Dial: Modeling Dialogues Grounded in Multiple Documents<br> NDH-Full: Learning and Evaluating Navigational Agents on Full-Length Dialogue<br> Simple Conversational Data Augmentation for Semi-supervised Abstractive Dialogue Summarization<br> Towards Automatic Evaluation of Dialog Systems: A Model-Free Off-Policy Evaluation Approach<br> Continual Learning in Task-Oriented Dialogue Systems<br> Investigating Robustness of Dialog Models to Popular Figurative Language Constructs<br> Effective Sequence-to-Sequence Dialogue State Tracking<br> Learning Neural Templates for Recommender Dialogue System<br> Proxy Indicators for the Quality of Open-domain Dialogues<br><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Q</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">Q^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>: Evaluating Factual Consistency in Knowledge-Grounded Dialogues via Question Generation and Question Answering<br> Knowledge-Aware Graph-Enhanced GPT-2 for Dialogue State Tracking<br> A Collaborative Multi-agent Reinforcement Learning Framework for Dialog Action Decomposition<br> Zero-Shot Dialogue State Tracking via Cross-Task Transfer<br> Uncertainty Measures in Neural Belief Tracking and the Effects on Dialogue Policy Performance<br> A Bag of Tricks for Dialogue Summarization<br> Is Information Density Uniform in Task-Oriented Dialogues<br> Code-switched inspired losses for spoken dialog representations<br> Looking for Confirmations: An Effective and Human-Like Visual Dialogue Strategy</p><h3 id="_2020-emnlp" tabindex="-1"><a class="header-anchor" href="#_2020-emnlp" aria-hidden="true">#</a> 2020 EMNLP</h3><p>Dialogue Response Ranking Training with Large-Scale Human Feedback Data<br> Where Are You? Localization from Embodied Dialog<br> Mitigating Gender Bias for Neural Dialogue Generation with Adversarial Learning<br> Will I Sound Like Me? Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness<br> TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue<br> RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling<br> Filtering Noisy Dialogue Corpora by Connectivity and Content Relatedness<br> BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues<br> UniConv: A Unified Conversational Neural Architecture for Multi-domain Task-oriented Dialogues<br> GraphDialog: Integrating Graph Knowledge into End-to-End Task-Oriented Dialogue Systems<br> Structured Attention for Unsupervised Dialogue Structure Induction<br> Cross Copy Network for Dialogue Generation<br> Multi-turn Response Selection using Dialogue Dependency Relations<br> Parallel Interactive Networks for Multi-Domain Dialogue State Generation<br> How to Make Neural Natural Language Generation as Reliable as Templates in Task-Oriented Dialogue<br> Slot Attention with Value Normalization for Multi-Domain Dialogue State Tracking<br> A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses<br> VD-BERT: A Unified Vision and Dialog Transformer with BERT<br> Knowledge-Grounded Dialogue Generation with Pre-trained Language Models<br> MinTL: Minimalist Transfer Learning for Task-Oriented Dialogue Systems<br> Variational Hierarchical Dialog Autoencoder for Dialog State Tracking Data Augmentation<br> Bridging the Gap between Prior and Posterior Knowledge Selection for Knowledge-Grounded Dialogue Generation<br> Counterfactual Off-Policy Training for Neural Dialogue Generation<br> Dialogue Distillation: Open-Domain Dialogue Augmentation Using Unpaired Data<br> Task-Completion Dialogue Policy Learning via Monte Carlo Tree Search with Dueling Network<br> AttnIO: Knowledge Graph Exploration with In-and-Out Attention Flow for Knowledge-Grounded Dialogue<br> Amalgamating Knowledge from Two Teachers for Task-oriented Dialogue System with Adversarial Training<br> Spot The Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems<br> Human-centric dialog training via offline reinforcement learning<br> Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization<br> Generating Dialogue Responses from a Semantic Latent Space<br> Probing Task-Oriented Dialogue Representation from Language Models<br> Simple Data Augmentation with the Mask Token Improves Domain Adaptation for Dialog Act Tagging<br> Sound Natural: Content Rephrasing in Dialog Systems<br> Template Guided Text Generation for Task-Oriented Dialogue<br> Regularizing Dialogue Generation by Imitating Implicit Scenarios<br> Semantic Role Labeling Guided Multi-turn Dialogue ReWriter<br> Profile Consistency Identification for Open-domain Dialogue Agents<br> Conversational Semantic Parsing for Dialog State Tracking<br> doc2dial: A Goal-Oriented Document-Grounded Dialogue Dataset<br> Interview: Large-scale Modeling of Media Dialog with Discourse Patterns and Knowledge Grounding<br> INSPIRED: Toward Sociable Recommendation Dialog Systems<br> Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation<br> Like hiking? You probably enjoy nature: Persona-grounded Dialog with Commonsense Expansions<br> A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning<br> The World is Not Binary: Learning to Rank with Grayscale Data for Dialogue Response Selection<br> GRADE: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems<br> MedDialog: Large-scale Medical Dialogue Datasets</p><h3 id="_2019-emnlp" tabindex="-1"><a class="header-anchor" href="#_2019-emnlp" aria-hidden="true">#</a> 2019 EMNLP</h3><p>LIDA: Lightweight Interactive Dialogue Annotator<br> PolyResponse: A Rank-based Approach to Task-Oriented Dialogue with Application in Restaurant Search and Booking<br> PyOpenDial: A Python-based Domain-Independent Toolkit for Developing Spoken Dialogue Systems with Probabilistic Rules<br> Guided Dialog Policy Learning: Reward Estimation for Multi-Domain Task-Oriented Dialog<br> Entity-Consistent End-to-end Task-Oriented Dialogue System with KB Retriever<br> Building Task-Oriented Visual Dialog Systems Through Alternative Optimization Between Dialog Policy and Language Generation<br> DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation<br> Using Customer Service Dialogues for Satisfaction Analysis with Context-Assisted Multiple Instance Learning<br> Multi-task Learning for Natural Language Generation in Task-Oriented Dialogue<br> Dirichlet Latent Variable Hierarchical Recurrent Encoder-Decoder in Dialogue Generation<br> Semi-Supervised Bootstrapping of Dialogue State Trackers for Task-Oriented Modelling<br> Sampling Matters! An Empirical Study of Negative Sampling Strategies for Learning of Matching Models in Retrieval-based Dialogue Systems<br> Zero-shot Cross-lingual Dialogue Systems with Transferable Latent Variables<br> Modeling Multi-Action Policy for Task-Oriented Dialogues<br> Automatically Learning Data Augmentation Policies for Dialogue Tasks<br> Improving Generative Visual Dialog by Answering Diverse Questions<br> Dependency Parsing for Spoken Dialog Systems<br> Span-based Hierarchical Semantic Parsing for Task-Oriented Dialog<br> Data-Efficient Goal-Oriented Conversation with Dialogue Knowledge Transfer Networks<br> Multi-Granularity Representations of Dialog<br> Are You for Real? Detecting Identity Fraud via Dialogue Interactions<br> Adaptive Parameterization for Neural Dialogue Generation<br> Towards Knowledge-Based Recommender Dialog System<br> Improving Open-Domain Dialogue Systems via Multi-Turn Incomplete Utterance Restoration<br> DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic Knowledge Graphs<br> Retrieval-guided Dialogue Response Generation via a Matching-to-Generation Framework<br> Scalable and Accurate Dialogue State Tracking via Hierarchical Sequence Generation<br> A Semi-Supervised Stable Variational Network for Promoting Replier-Consistency in Dialogue Generation<br> Recommendation as a Communication Game: Self-Supervised Bot-Play for Goal-oriented Dialogue<br> A Practical Dialogue-Act-Driven Conversation Model for Multi-Turn Response Selection<br> How to Build User Simulators to Train RL-based Dialog Systems<br> Dual Attention Networks for Visual Reference Resolution in Visual Dialog<br> Video Dialog via Progressive Inference and Cross-Transformer<br> Dialog Intent Induction with Deep Multi-View Clustering<br> Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset<br> Multi-Domain Goal-Oriented Dialogues (MultiDoGO): Strategies toward Curating and Annotating Large Scale Dialogue Data<br> Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack<br> GECOR: An End-to-End Generative Ellipsis and Co-reference Resolution Model for Task-Oriented Dialogue<br> Enhancing Dialogue Symptom Diagnosis with Global Attention and Symptom Graph<br> What You See is What You Get: Visual Pronoun Coreference Resolution in Dialogues</p><h2 id="acl" tabindex="-1"><a class="header-anchor" href="#acl" aria-hidden="true">#</a> ACL</h2><h3 id="_2023-acl" tabindex="-1"><a class="header-anchor" href="#_2023-acl" aria-hidden="true">#</a> 2023 ACL</h3><p>ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?<br> Controllable Mixed-Initiative Dialogue Generation through Prompting<br> Towards Fewer Hallucinations in Knowledge-Grounded Dialogue Generation via Augmentative and Contrastive Knowledge-Dialogue<br> One Cannot Stand for Everyone! Leveraging Multiple User Simulators to train Task-oriented Dialogue Systems<br> Span-Selective Linear Attention Transformers for Effective and Robust Schema-Guided Dialogue State Tracking<br> EM Pre-training for Multi-party Dialogue Response Generation<br> Evaluating Open-Domain Dialogues in Latent Space with Next Sentence Prediction and Mutual Information<br> DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data Augmentation in Multi-Turn Conversations<br> DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization<br> White-Box Multi-Objective Adversarial Attack on Dialogue Generation<br> Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking<br> Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues<br> MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via Moral Discussions<br> Injecting knowledge into language generation: a case study in auto-charting after-visit care instructions from medical dialogue<br> BREAK: Breaking the Dialogue State Tracking Barrier with Beam Search and Re-ranking<br> Learning to Generate Equitable Text in Dialogue from Biased Training Data<br> CORE: Cooperative Training of Retriever-Reranker for Effective Dialogue Response Selection<br> PVGRU: Generating Diverse and Relevant Dialogue Responses via Pseudo-Variational Mechanism<br> DAMP: Doubly Aligned Multilingual Parser for Task-Oriented Dialogue<br> Knowledge-enhanced Mixed-initiative Dialogue System for Emotional Support Conversations<br> ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems<br> Towards Faithful Dialogues via Focus Learning<br> Prompter: Zero-shot Adaptive Prefixes for Dialogue State Tracking Domain Adaptation<br> Enhancing Dialogue Generation via Dynamic Graph Knowledge Aggregation<br> VSTAR: A Video-grounded Dialogue Dataset for Situated Semantic Understanding with Scene and Topic Transitions<br> Enhancing Personalized Dialogue Generation with Contrastive Latent Variables: Combining Sparse and Dense Persona<br> SIMMC-VR: A Task-oriented Multimodal Dialog Dataset with Situated and Immersive VR Streams<br> FutureTOD: Teaching Future Knowledge to Pre-trained Language Model for Task-Oriented Dialogue<br> Retrieval-free Knowledge Injection through Multi-Document Traversal for Dialogue Models<br> Annotating and Detecting Fine-grained Factual Errors for Dialogue Summarization<br> MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal Open-domain Conversation<br> Envisioning Future from the Past: Hierarchical Duality Learning for Multi-Turn Dialogue Generation<br> Using Domain Knowledge to Guide Dialog Structure Induction via Neural Probabilistic Soft Logic<br> A Dataset of Argumentative Dialogues on Scientific Papers<br> Contextual Knowledge Learning for Dialogue Generation<br> Speech-Text Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment<br> MidMed: Towards Mixed-Type Dialogues for Medical Consultation<br> RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized Dialogue Response Generation<br> Modeling User Satisfaction Dynamics in Dialogue via Hawkes Process<br> Pre-training Multi-party Dialogue Models with Latent Discourse Inference<br> PAED: Zero-Shot Persona Attribute Extraction in Dialogues<br> SimOAP: Improve Coherence and Consistency in Persona-based Dialogue Generation via Over-sampling and Post-evaluation<br> Dialog-Post: Multi-Level Self-Supervised Objectives and Hierarchical Model for Dialogue Post-Training<br> A Cognitive Stimulation Dialogue System with Multi-source Knowledge Fusion for Elders with Cognitive Impairment<br> A Synthetic Data Generation Framework for Grounded Dialogues<br> Multi-Grained Knowledge Retrieval for End-to-End Task-Oriented Dialog<br> XDailyDialog: A Multilingual Parallel Dialogue Corpus<br> RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue<br> PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and Compositional Experts<br> Learning New Skills after Deployment: Improving open-domain internet-driven dialogue with human feedback<br> On the Compositional Generalization in Versatile Open-domain Dialogue<br> Dialogue Summarization with Static-Dynamic Structure Fusion Graph<br> Reference Matters: Benchmarking Factual Error Correction for Dialogue Summarization with Fine-grained Evaluation Framework<br> Multimodal Persona Based Generation of Comic Dialogs<br> Seen to Unseen: Exploring Compositional Generalization of Multi-Attribute Controllable Dialogue Generation<br> Towards Understanding Omission in Dialogue Summarization<br> Don&#39;t Forget Your ABC&#39;s: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems<br> LiveChat: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming</p><h3 id="_2022-acl" tabindex="-1"><a class="header-anchor" href="#_2022-acl" aria-hidden="true">#</a> 2022 ACL</h3><p>Learning-by-Narrating: Narrative Pre-Training for Zero-Shot Dialogue Comprehension<br> Mismatch between Multi-turn Dialogue and its Evaluation Metric in Dialogue State Tracking<br> Towards Fair Evaluation of Dialogue State Tracking by Flexible Incorporation of Turn-level Performances<br> UniGDD: A Unified Generative Framework for Goal-Oriented Document-Grounded Dialogue<br> Investigating person-specific errors in chat-oriented dialogue systems<br> Can Visual Dialogue Models Do Scorekeeping? Exploring How Dialogue Representations Incrementally Encode Shared Knowledge<br> [CASPI] Causal-aware Safe Policy Improvement for Task-oriented Dialogue<br> UniTranSeR: A Unified Transformer Semantic Representation Framework for Multimodal Task-Oriented Dialog System<br> Dynamic Schema Graph Fusion Network for Multi-Domain Dialogue State Tracking<br> Structural Characterization for Dialogue Disentanglement<br> Multi-Party Empathetic Dialogue Generation: A New Task for Dialog Systems<br> DEAM: Dialogue Coherence Evaluation using AMR-based Semantic Manipulations<br> ProphetChat: Enhancing Dialogue Generation with Simulation of Future Conversation<br> Where to Go for the Holidays: Towards Mixed-Type Dialogs for Clarification of User Goals<br> Continual Prompt Tuning for Dialog State Tracking<br> Online Semantic Parsing for Latency Reduction in Task-Oriented Dialogue<br> Summ<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mi>N</mi></msup></mrow><annotation encoding="application/x-tex">^N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span></span></span></span></span></span></span>: A Multi-Stage Summarization Framework for Long Input Dialogues and Documents<br> GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems<br> Beyond the Granularity: Multi-Perspective Dialogue Collaborative Selection for Dialogue State Tracking<br> Other Roles Matter! Enhancing Role-Oriented Dialogue Summarization via Role Interactions<br> Multimodal Dialogue Response Generation<br> A Taxonomy of Empathetic Questions in Social Dialogs<br> Knowledge Enhanced Reflection Generation for Counseling Dialogues<br> Improving Multi-label Malevolence Detection in Dialogues through Multi-faceted Label Correlation Enhancement<br> The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems<br> DialFact: A Benchmark for Fact-Checking in Dialogue<br> There Are a Thousand Hamlets in a Thousand People&#39;s Eyes: Enhancing Knowledge-grounded Dialogue with Personal Memory<br> Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System<br> DialogVED: A Pre-trained Latent Variable Encoder-Decoder Model for Dialog Response Generation<br> An Interpretable Neuro-Symbolic Reasoning Framework for Task-Oriented Dialogue Generation<br> CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues<br> M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database<br> What does the sea say to the shore? A BERT based DST style approach for speaker to dialogue attribution in novels<br> When did you become so smart, oh wise one?! Sarcasm Explanation in Multi-modal Multi-party Dialogues<br> SalesBot: Transitioning from Chit-Chat to Task-Oriented Dialogues<br> Achieving Reliable Human Assessment of Open-Domain Dialogue Systems<br> SaFeRDialogues: Taking Feedback Gracefully after Conversational Safety Failures<br> The AI Doctor Is In: A Survey of Task-Oriented Dialogue Systems for Healthcare Applications<br> Lexical Knowledge Internalization for Neural Dialog Generation<br> A Model-agnostic Data Manipulation Method for Persona-based Dialogue Generation<br> Situated Dialogue Learning through Procedural Environment Generation<br> Internet-Augmented Dialogue Generation</p><h3 id="_2021-acl" tabindex="-1"><a class="header-anchor" href="#_2021-acl" aria-hidden="true">#</a> 2021 ACL</h3><p>Saying No is An Art: Contextualized Fallback Responses for Unanswerable Dialogue Queries<br> PRAL: A Tailored Pre-Training Model for Task-Oriented Dialog Generation<br> Continual Learning for Task-oriented Dialogue System with Iterative Network Pruning, Expanding and Masking<br> Unsupervised Enrichment of Persona-grounded Dialog with Background Stories<br> Domain-Adaptive Pretraining Methods for Dialogue Understanding<br> Preview, Attend and Review: Schema-Aware Curriculum Learning for Multi-Domain Dialogue State Tracking<br> On the Generation of Medical Dialogs for COVID-19<br> Constructing Multi-Modal Dialogue Dataset by Replacing Text with Semantically Relevant Images<br> Conversations Are Not Flat: Modeling the Dynamic Information Flow across Dialogue Utterances<br> Dual Slot Selector via Local Reliability Verification for Dialogue State Tracking<br> Transferable Dialogue Systems and User Simulators<br> BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data<br> SocAoG: Incremental Graph Parsing for Social Relation Inference in Dialogues<br> TicketTalk: Toward human-level performance with end-to-end, transaction-based dialog systems<br> Improving Dialog Systems for Negotiation with Personality Modeling<br> Learning from Perturbations: Diverse and Informative Dialogue Generation with Inverse Adversarial Training<br> Increasing Faithfulness in Knowledge-Grounded Dialogue with Controllable Features<br> Prosodic segmentation for parsing spoken dialogue<br> Language Model as an Annotator: Exploring DialoGPT for Dialogue Summarization<br> Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection<br> I like fish, especially dolphins: Addressing Contradictions in Dialogue Modeling<br> Discovering Dialog Structure Graph for Coherent Dialog Generation<br> A Sequence-to-Sequence Approach to Dialogue State Tracking<br> Dialogue Response Selection with Hierarchical Curriculum Learning<br> Discovering Dialogue Slots with Weak Supervision<br> Robustness Testing of Language Understanding in Task-Oriented Dialog<br> Comprehensive Study: How the Context Information of Different Granularity Affects Dialogue State Tracking?<br> OTTers: One-turn Topic Transitions for Open-Domain Dialogue<br> Towards Quantifiable Dialogue Coherence Evaluation<br> Novel Slot Detection: A Benchmark for Discovering Unknown Slot Types in the Task-Oriented Dialogue System<br> Towards Emotional Support Dialog Systems<br> Diversifying Dialog Generation via Adaptive Label Smoothing<br> NeuralWOZ: Learning to Collect Task-Oriented Dialogue via Model-Based Simulation<br> RADDLE: An Evaluation Benchmark and Analysis Platform for Robust Task-oriented Dialog Systems<br> Semantic Representation for Dialogue Modeling<br> Structural Pre-training for Dialogue Comprehension<br> A Human-machine Collaborative Framework for Evaluating Malevolence in Dialogues<br> Generating Relevant and Coherent Dialogue Responses using Self-Separated Conditional Variational AutoEncoders<br> DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded Dialogue<br> DynaEval: Unifying Turn and Dialogue Level Evaluation<br> RepSum: Unsupervised Dialogue Summarization based on Replacement Strategy<br> PhotoChat: A Human-Human Dialogue Dataset With Photo Sharing Behavior For Joint Image-Text Modeling<br> Space Efficient Context Encoding for Non-Task-Oriented Dialogue Generation with Graph Attention Transformer<br> DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations<br> TIMEDIAL: Temporal Commonsense Reasoning in Dialog</p><h3 id="_2020-acl" tabindex="-1"><a class="header-anchor" href="#_2020-acl" aria-hidden="true">#</a> 2020 ACL</h3><p>ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and Diagnosing Dialogue Systems<br> DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation<br> Conversation Learner - A Machine Teaching Tool for Building Dialog Managers for Task-Oriented Dialog Systems<br> Designing Precise and Robust Dialogue Response Evaluators<br> Dialogue State Tracking with Explicit Slot Connection Modeling<br> Large Scale Multi-Actor Generative Dialog Modeling<br> PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable<br> Slot-consistent NLG for Task-oriented Dialogue Systems with Iterative Rectification Network<br> Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained Conversational Representations<br> Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking<br> Efficient Dialogue State Tracking by Selectively Overwriting Memory<br> End-to-End Neural Pipeline for Goal-Oriented Dialogue Systems using GPT-2<br> Evaluating Dialogue Generation Systems via Response Selection<br> Learning Low-Resource End-To-End Goal-Oriented Dialog for Fast and Reliable System Deployment<br> Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward Decomposition<br> Paraphrase Augmented Task-Oriented Dialog Generation<br> Semi-Supervised Dialogue Policy Learning via Stochastic Reward Estimation<br> USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation<br> Towards Conversational Recommendation over Multi-Type Dialogs<br> Crawling and Preprocessing Mailing Lists At Scale for Dialog Analysis<br> Beyond User Self-Reported Likert Scale Ratings: A Comparison Model for Automatic Dialog Evaluation<br> Conversational Word Embedding for Retrieval-Based Dialog System<br> Learning Dialog Policies from Weak Demonstrations<br> MuTual: A Dataset for Multi-Turn Dialogue Reasoning<br> You Impress Me: Dialogue Generation via Mutual Persona Perception<br> Dialogue Coherence Assessment Without Explicit Dialogue Act Labels<br> &quot;None of the Above&quot;: Measure Uncertainty in Dialog Response Retrieval<br> Negative Training for Neural Dialogue Response Generation<br> Recursive Template-based Frame Generation for Task Oriented Dialog<br> Grounding Conversations with Improvised Dialogues<br> Learning an Unreferenced Metric for Online Dialogue Evaluation<br> Neural Generation of Dialogue Response Timings<br> The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents<br> Learning to execute instructions in a Minecraft dialogue<br> ChartDialogs: Plotting from Natural Language Instructions<br> Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation<br> Towards Emotion-aided Multi-modal Dialogue Act Classification<br> Don&#39;t Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood Training<br> Dialogue-Based Relation Extraction<br> More Diverse Dialogue Datasets via Diversity-Informed Data Collection<br> Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset<br> Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for Span-based Question Answering<br> Diverse and Informative Dialogue Generation with Context-Specific Commonsense Knowledge Awareness<br> Generate, Delete and Rewrite: A Three-Stage Framework for Improving Persona Consistency of Dialogue Generation<br> Learning to Customize Model Structures for Few-shot Dialogue Generation Tasks<br> Video-Grounded Dialogues with Pretrained Generation Language Models<br> A Contextual Hierarchical Attention Network with Adaptive Objective for Dialogue State Tracking<br> Data Manipulation: Towards Effective Instance Learning for Neural Dialogue Generation via Learning to Augment and Reweight<br> Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog<br> Learning Efficient Dialogue Policy from Demonstrations through Shaping<br> SAS: Dialogue State Tracking via Slot Attention and Slot Information Sharing<br> MIE: A Medical Information Extractor towards Medical Dialogues<br> Diversifying Dialogue Generation with Non-Conversational Text<br> KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation<br> Meta-Reinforced Multi-Domain State Generator for Dialogue Systems<br> Modeling Long Context for Task-Oriented Dialogue State Generation<br> Multi-Domain Dialogue Acts and Response Co-Generation<br> History for Visual Dialog: Do we really need it?</p><h3 id="_2019-acl" tabindex="-1"><a class="header-anchor" href="#_2019-acl" aria-hidden="true">#</a> 2019 ACL</h3><p>Dialogue-Act Prediction of Future Responses Based on Conversation History<br> One Time of Interaction May Not Be Enough: Go Deep with an Interaction-over-Interaction Network for Response Selection in Dialogues<br> Improving Multi-turn Dialogue Modelling with Utterance ReWriter<br> Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study<br> Boosting Dialog Response Generation<br> Implicit Discourse Relation Identification for Open-domain Dialogues<br> Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems<br> Constrained Decoding for Neural NLG from Compositional Representations in Task-Oriented Dialogue<br> Domain Adaptive Dialog Generation via Meta Learning<br> The PhotoBook Dataset: Building Common Ground through Visually-Grounded Dialogue<br> Learning from Dialogue after Deployment: Feed Yourself, Chatbot!<br> A Working Memory Model for Task-oriented Dialog Response Generation<br> Generating Responses with a Specific Emotion in Dialog<br> Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention<br> ReCoSa: Detecting the Relevant Contexts with Self-Attention for Multi-turn Dialogue Generation<br> Incremental Learning from Scratch for Task-Oriented Dialogue Systems<br> Dialogue Natural Language Inference<br> Budgeted Policy Learning for Task-Oriented Dialogue Systems<br> Learning a Matching Model with Co-teaching for Multi-turn Response Selection in Retrieval-based Dialogue Systems<br> Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References<br> Pretraining Methods for Dialog Context Representation Learning<br> Self-Supervised Dialogue Learning<br> Know More about Each Other: Evolving Dialogue Strategy via Compound Assessment<br> Training Neural Response Selection for Task-Oriented Dialogue Systems<br> Collaborative Dialogue in Minecraft<br> Ordinal and Attribute Aware Response Generation in a Multimodal Dialogue System<br> Memory Consolidation for Contextual Spoken Language Understanding with Dialogue Logistic Inference<br> Personalizing Dialogue Agents via Meta-Learning<br> Reading Turn by Turn: Hierarchical Attention Architecture for Spoken Dialogue Comprehension<br> Rationally Reappraising ATIS-based Dialogue Systems<br> Observing Dialogue in Therapy: Categorizing and Forecasting Behavioral Codes<br> Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems<br> Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good<br> What Should I Ask? Using Conversationally Informative Rewards for Goal-oriented Visual Dialog<br> Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog</p></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/vuepress-theme-hope/vuepress-theme-hope/edit/main/src/keyan/dialog.md" rel="noopener noreferrer" target="_blank" aria-label="åœ¨ GitHub ä¸Šç¼–è¾‘æ­¤é¡µ" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->åœ¨ GitHub ä¸Šç¼–è¾‘æ­¤é¡µ<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item git-info"><div class="update-time"><span class="label">ä¸Šæ¬¡ç¼–è¾‘äº: </span><!----></div><div class="contributors"><span class="label">è´¡çŒ®è€…: </span><!--[--><!--[--><span class="contributor" title="email: 799976781@qq.com">WillebrordSnell</span><!--]--><!--]--></div></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">è¥¿æ¹–ç¾æ™¯, ä¸‰æœˆå¤©å˜~</div><div class="vp-copyright">Copyright Â© 2023 Mr.R</div></footer></div><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-69065092.js" defer></script>
  </body>
</html>
