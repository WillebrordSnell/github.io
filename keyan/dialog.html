<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.67" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="https://github.com/WillebrordSnell/keyan/dialog.html"><meta property="og:site_name" content=" "><meta property="og:title" content="ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†"><meta property="og:description" content="ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›† æœ¬æ–‡ä¸»è¦è®°å½•ä¸€ä¸‹è¿‘4å¹´(2019å¹´èµ·)å„é¡¶ä¼šé¡¶åˆŠæœ‰å…³dialogçš„paperåå­—ï¼Œä»¥ä¾¿åç»­video dialogå·¥ä½œçš„è°ƒç ”å’Œå±•å¼€ (æœ¬æ–‡æ¡£æœªç»è¿‡ä»»ä½•ç­›é€‰ï¼Œä»…é€šè¿‡å…³é”®è¯æœç´¢å¾—åˆ°paperåå­—) æ¨èäºŒçº§æ£€ç´¢å…³é”®è¯ï¼šhistory ã€ generaã€ visualã€ Supervisã€ videoç­‰ ECCV 2022 ECCV New Datasets and Models for Contextual Reasoning in Visual Dialog Video Dialog as Conversation About Objects Living in Space-Time"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2023-10-18T15:20:18.000Z"><meta property="article:author" content="Mr.R"><meta property="article:tag" content="å»ç å¤´æ•´ç‚¹è®ºæ–‡"><meta property="article:published_time" content="2023-09-19T00:00:00.000Z"><meta property="article:modified_time" content="2023-10-18T15:20:18.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†","image":[""],"datePublished":"2023-09-19T00:00:00.000Z","dateModified":"2023-10-18T15:20:18.000Z","author":[{"@type":"Person","name":"Mr.R","url":"https://github.com/WillebrordSnell"}]}</script><title>ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›† |  </title><meta name="description" content="ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›† æœ¬æ–‡ä¸»è¦è®°å½•ä¸€ä¸‹è¿‘4å¹´(2019å¹´èµ·)å„é¡¶ä¼šé¡¶åˆŠæœ‰å…³dialogçš„paperåå­—ï¼Œä»¥ä¾¿åç»­video dialogå·¥ä½œçš„è°ƒç ”å’Œå±•å¼€ (æœ¬æ–‡æ¡£æœªç»è¿‡ä»»ä½•ç­›é€‰ï¼Œä»…é€šè¿‡å…³é”®è¯æœç´¢å¾—åˆ°paperåå­—) æ¨èäºŒçº§æ£€ç´¢å…³é”®è¯ï¼šhistory ã€ generaã€ visualã€ Supervisã€ videoç­‰ ECCV 2022 ECCV New Datasets and Models for Contextual Reasoning in Visual Dialog Video Dialog as Conversation About Objects Living in Space-Time">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-512ce842.css" as="style"><link rel="stylesheet" href="/assets/style-512ce842.css">
    <link rel="modulepreload" href="/assets/app-b95f5b1a.js"><link rel="modulepreload" href="/assets/dialog.html-1030d135.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-c27b6911.js"><link rel="modulepreload" href="/assets/dialog.html-67f127ce.js"><link rel="prefetch" href="/assets/index.html-d9458bfe.js" as="script"><link rel="prefetch" href="/assets/intro.html-2e5e4af5.js" as="script"><link rel="prefetch" href="/assets/slides.html-fd5a002b.js" as="script"><link rel="prefetch" href="/assets/202309.html-74c2b100.js" as="script"><link rel="prefetch" href="/assets/202310.html-5598bf6d.js" as="script"><link rel="prefetch" href="/assets/202311.html-9c2dc3ef.js" as="script"><link rel="prefetch" href="/assets/maoxuan.html-02808c56.js" as="script"><link rel="prefetch" href="/assets/index.html-bf1750b6.js" as="script"><link rel="prefetch" href="/assets/disable.html-28c49317.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-0f38acb2.js" as="script"><link rel="prefetch" href="/assets/markdown.html-d32d3131.js" as="script"><link rel="prefetch" href="/assets/page.html-d359f584.js" as="script"><link rel="prefetch" href="/assets/index.html-aed730ad.js" as="script"><link rel="prefetch" href="/assets/video.html-b54bb940.js" as="script"><link rel="prefetch" href="/assets/index.html-a3a40393.js" as="script"><link rel="prefetch" href="/assets/index.html-3b3fc455.js" as="script"><link rel="prefetch" href="/assets/markdown01.html-8905e9eb.js" as="script"><link rel="prefetch" href="/assets/markdown02.html-054a564a.js" as="script"><link rel="prefetch" href="/assets/index.html-1c6f8d12.js" as="script"><link rel="prefetch" href="/assets/contrastiveLearning.html-5bd139be.js" as="script"><link rel="prefetch" href="/assets/multiModal.html-c152230c.js" as="script"><link rel="prefetch" href="/assets/videoDialog.html-6d0bd465.js" as="script"><link rel="prefetch" href="/assets/videoRepresentation.html-86cfe134.js" as="script"><link rel="prefetch" href="/assets/videoUnderstanding.html-d7d9f06e.js" as="script"><link rel="prefetch" href="/assets/Bloodborne.html-ac9206cd.js" as="script"><link rel="prefetch" href="/assets/DeathStranding.html-d5380b1b.js" as="script"><link rel="prefetch" href="/assets/AVSD.html-2a3fce88.js" as="script"><link rel="prefetch" href="/assets/DDP.html-d779b619.js" as="script"><link rel="prefetch" href="/assets/trick.html-bb31f35e.js" as="script"><link rel="prefetch" href="/assets/index.html-a202766c.js" as="script"><link rel="prefetch" href="/assets/manual01.html-0a8da7f1.js" as="script"><link rel="prefetch" href="/assets/manual02.html-d7e0e274.js" as="script"><link rel="prefetch" href="/assets/manual03.html-fc2fcb88.js" as="script"><link rel="prefetch" href="/assets/index.html-94ec1b0f.js" as="script"><link rel="prefetch" href="/assets/documentnotes01.html-3e3bf028.js" as="script"><link rel="prefetch" href="/assets/documentnotes02.html-b0ab3628.js" as="script"><link rel="prefetch" href="/assets/documentnotes03.html-dffc6ca6.js" as="script"><link rel="prefetch" href="/assets/documentnotes04.html-5c8e168f.js" as="script"><link rel="prefetch" href="/assets/documentnotes05.html-e6c9c3ad.js" as="script"><link rel="prefetch" href="/assets/documentnotes06.html-8351650a.js" as="script"><link rel="prefetch" href="/assets/documentnotes07.html-a1156cd2.js" as="script"><link rel="prefetch" href="/assets/documentnotes08.html-4dd750d8.js" as="script"><link rel="prefetch" href="/assets/documentnotes09.html-c3df51ca.js" as="script"><link rel="prefetch" href="/assets/documentnotes10.html-22d25bd9.js" as="script"><link rel="prefetch" href="/assets/documentnotes11.html-739f34bd.js" as="script"><link rel="prefetch" href="/assets/404.html-33087db7.js" as="script"><link rel="prefetch" href="/assets/index.html-f543ab52.js" as="script"><link rel="prefetch" href="/assets/index.html-edca5983.js" as="script"><link rel="prefetch" href="/assets/index.html-9e922b59.js" as="script"><link rel="prefetch" href="/assets/index.html-5d327b0f.js" as="script"><link rel="prefetch" href="/assets/index.html-64a9f81e.js" as="script"><link rel="prefetch" href="/assets/index.html-1eb7a45d.js" as="script"><link rel="prefetch" href="/assets/index.html-3b8e3fc4.js" as="script"><link rel="prefetch" href="/assets/index.html-c24f66de.js" as="script"><link rel="prefetch" href="/assets/index.html-b28248cf.js" as="script"><link rel="prefetch" href="/assets/index.html-11a8a3d5.js" as="script"><link rel="prefetch" href="/assets/index.html-5f4f46c8.js" as="script"><link rel="prefetch" href="/assets/index.html-3fa1430b.js" as="script"><link rel="prefetch" href="/assets/index.html-50095564.js" as="script"><link rel="prefetch" href="/assets/index.html-170b7dac.js" as="script"><link rel="prefetch" href="/assets/index.html-4450e009.js" as="script"><link rel="prefetch" href="/assets/index.html-cd5496ff.js" as="script"><link rel="prefetch" href="/assets/index.html-bf5da18c.js" as="script"><link rel="prefetch" href="/assets/index.html-789dc91d.js" as="script"><link rel="prefetch" href="/assets/index.html-598316da.js" as="script"><link rel="prefetch" href="/assets/index.html-deffa58c.js" as="script"><link rel="prefetch" href="/assets/index.html-cc90af66.js" as="script"><link rel="prefetch" href="/assets/index.html-78e1edef.js" as="script"><link rel="prefetch" href="/assets/index.html-95c6778e.js" as="script"><link rel="prefetch" href="/assets/index.html-ef15ab18.js" as="script"><link rel="prefetch" href="/assets/index.html-de15c52f.js" as="script"><link rel="prefetch" href="/assets/index.html-3ffa64a8.js" as="script"><link rel="prefetch" href="/assets/index.html-0c4ebc78.js" as="script"><link rel="prefetch" href="/assets/index.html-7c39f58a.js" as="script"><link rel="prefetch" href="/assets/index.html-dc0cfaa1.js" as="script"><link rel="prefetch" href="/assets/index.html-e6f556de.js" as="script"><link rel="prefetch" href="/assets/index.html-996c738c.js" as="script"><link rel="prefetch" href="/assets/index.html-946da1ee.js" as="script"><link rel="prefetch" href="/assets/index.html-30e4e921.js" as="script"><link rel="prefetch" href="/assets/index.html-e2a85053.js" as="script"><link rel="prefetch" href="/assets/index.html-41d7be7d.js" as="script"><link rel="prefetch" href="/assets/index.html-36154924.js" as="script"><link rel="prefetch" href="/assets/index.html-334a54b6.js" as="script"><link rel="prefetch" href="/assets/index.html-2ae1afae.js" as="script"><link rel="prefetch" href="/assets/index.html-0c3db965.js" as="script"><link rel="prefetch" href="/assets/index.html-6b1ed3d2.js" as="script"><link rel="prefetch" href="/assets/index.html-4e97df2f.js" as="script"><link rel="prefetch" href="/assets/index.html-c038150d.js" as="script"><link rel="prefetch" href="/assets/intro.html-a85a62d4.js" as="script"><link rel="prefetch" href="/assets/slides.html-714a55f7.js" as="script"><link rel="prefetch" href="/assets/202309.html-ad4bac2f.js" as="script"><link rel="prefetch" href="/assets/202310.html-e6d41310.js" as="script"><link rel="prefetch" href="/assets/202311.html-219c9398.js" as="script"><link rel="prefetch" href="/assets/maoxuan.html-d9a81bc4.js" as="script"><link rel="prefetch" href="/assets/index.html-c4573534.js" as="script"><link rel="prefetch" href="/assets/disable.html-4d874ee3.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-e0638cfb.js" as="script"><link rel="prefetch" href="/assets/markdown.html-1996ac02.js" as="script"><link rel="prefetch" href="/assets/page.html-5f209caa.js" as="script"><link rel="prefetch" href="/assets/index.html-564c0198.js" as="script"><link rel="prefetch" href="/assets/video.html-9881af8a.js" as="script"><link rel="prefetch" href="/assets/index.html-7184743d.js" as="script"><link rel="prefetch" href="/assets/index.html-c85ca45c.js" as="script"><link rel="prefetch" href="/assets/markdown01.html-1b57a525.js" as="script"><link rel="prefetch" href="/assets/markdown02.html-73209be5.js" as="script"><link rel="prefetch" href="/assets/index.html-7afca7c1.js" as="script"><link rel="prefetch" href="/assets/contrastiveLearning.html-da520270.js" as="script"><link rel="prefetch" href="/assets/multiModal.html-f759a16e.js" as="script"><link rel="prefetch" href="/assets/videoDialog.html-5b274b9f.js" as="script"><link rel="prefetch" href="/assets/videoRepresentation.html-f0bcdf6d.js" as="script"><link rel="prefetch" href="/assets/videoUnderstanding.html-d8c07809.js" as="script"><link rel="prefetch" href="/assets/Bloodborne.html-92d64cd7.js" as="script"><link rel="prefetch" href="/assets/DeathStranding.html-bf5b3c3a.js" as="script"><link rel="prefetch" href="/assets/AVSD.html-547001a6.js" as="script"><link rel="prefetch" href="/assets/DDP.html-ad9f78a7.js" as="script"><link rel="prefetch" href="/assets/trick.html-e090a611.js" as="script"><link rel="prefetch" href="/assets/index.html-473f40bf.js" as="script"><link rel="prefetch" href="/assets/manual01.html-5e13659e.js" as="script"><link rel="prefetch" href="/assets/manual02.html-afd23a71.js" as="script"><link rel="prefetch" href="/assets/manual03.html-1c9cc728.js" as="script"><link rel="prefetch" href="/assets/index.html-0ccc0ad4.js" as="script"><link rel="prefetch" href="/assets/documentnotes01.html-eca01c0d.js" as="script"><link rel="prefetch" href="/assets/documentnotes02.html-f560ab17.js" as="script"><link rel="prefetch" href="/assets/documentnotes03.html-d6d97f06.js" as="script"><link rel="prefetch" href="/assets/documentnotes04.html-a71918ef.js" as="script"><link rel="prefetch" href="/assets/documentnotes05.html-d8014fb1.js" as="script"><link rel="prefetch" href="/assets/documentnotes06.html-56a69294.js" as="script"><link rel="prefetch" href="/assets/documentnotes07.html-186f1935.js" as="script"><link rel="prefetch" href="/assets/documentnotes08.html-50d235f9.js" as="script"><link rel="prefetch" href="/assets/documentnotes09.html-5286bef4.js" as="script"><link rel="prefetch" href="/assets/documentnotes10.html-5dfd76da.js" as="script"><link rel="prefetch" href="/assets/documentnotes11.html-e4850c6d.js" as="script"><link rel="prefetch" href="/assets/404.html-dc36e228.js" as="script"><link rel="prefetch" href="/assets/index.html-9d464e81.js" as="script"><link rel="prefetch" href="/assets/index.html-097fb6c8.js" as="script"><link rel="prefetch" href="/assets/index.html-ea1a5e4b.js" as="script"><link rel="prefetch" href="/assets/index.html-df71a77e.js" as="script"><link rel="prefetch" href="/assets/index.html-22c27169.js" as="script"><link rel="prefetch" href="/assets/index.html-824f0b95.js" as="script"><link rel="prefetch" href="/assets/index.html-bcaea827.js" as="script"><link rel="prefetch" href="/assets/index.html-14dcce30.js" as="script"><link rel="prefetch" href="/assets/index.html-db49ea46.js" as="script"><link rel="prefetch" href="/assets/index.html-5545117b.js" as="script"><link rel="prefetch" href="/assets/index.html-82dac483.js" as="script"><link rel="prefetch" href="/assets/index.html-f462f838.js" as="script"><link rel="prefetch" href="/assets/index.html-3d9d4ee4.js" as="script"><link rel="prefetch" href="/assets/index.html-d53eb9b7.js" as="script"><link rel="prefetch" href="/assets/index.html-bde40e16.js" as="script"><link rel="prefetch" href="/assets/index.html-7df607f1.js" as="script"><link rel="prefetch" href="/assets/index.html-776a72d7.js" as="script"><link rel="prefetch" href="/assets/index.html-4e16c331.js" as="script"><link rel="prefetch" href="/assets/index.html-6d6c5547.js" as="script"><link rel="prefetch" href="/assets/index.html-7b865979.js" as="script"><link rel="prefetch" href="/assets/index.html-9db29a3b.js" as="script"><link rel="prefetch" href="/assets/index.html-bd8bc7c7.js" as="script"><link rel="prefetch" href="/assets/index.html-338ea78b.js" as="script"><link rel="prefetch" href="/assets/index.html-25d76b0f.js" as="script"><link rel="prefetch" href="/assets/index.html-a032948a.js" as="script"><link rel="prefetch" href="/assets/index.html-89aec90c.js" as="script"><link rel="prefetch" href="/assets/index.html-6eec349e.js" as="script"><link rel="prefetch" href="/assets/index.html-84c60365.js" as="script"><link rel="prefetch" href="/assets/index.html-77a2a2fb.js" as="script"><link rel="prefetch" href="/assets/index.html-424aea91.js" as="script"><link rel="prefetch" href="/assets/index.html-9181f7ca.js" as="script"><link rel="prefetch" href="/assets/index.html-f36d3b52.js" as="script"><link rel="prefetch" href="/assets/index.html-4f798113.js" as="script"><link rel="prefetch" href="/assets/index.html-8d9eeb16.js" as="script"><link rel="prefetch" href="/assets/index.html-38af90f9.js" as="script"><link rel="prefetch" href="/assets/index.html-e8c13b81.js" as="script"><link rel="prefetch" href="/assets/index.html-018afe71.js" as="script"><link rel="prefetch" href="/assets/index.html-1a63cb86.js" as="script"><link rel="prefetch" href="/assets/index.html-6291f3a8.js" as="script"><link rel="prefetch" href="/assets/index.html-f3b2b05b.js" as="script"><link rel="prefetch" href="/assets/index.html-f201eace.js" as="script"><link rel="prefetch" href="/assets/auto-fe80bb03.js" as="script"><link rel="prefetch" href="/assets/index-2bf332f6.js" as="script"><link rel="prefetch" href="/assets/flowchart-c441f34d.js" as="script"><link rel="prefetch" href="/assets/mermaid.core-451d8937.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-75b11b9d.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-9d5bc2ce.js" as="script"><link rel="prefetch" href="/assets/math.esm-70a288c8.js" as="script"><link rel="prefetch" href="/assets/notes.esm-a106bb2c.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-1a4c3ae7.js" as="script"><link rel="prefetch" href="/assets/search.esm-7e6792e2.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-b83b91d0.js" as="script"><link rel="prefetch" href="/assets/VuePlayground-a4f94031.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-5762295a.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">è·³è‡³ä¸»è¦å…§å®¹</a><!--]--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/"><img class="vp-nav-logo" src="/logo.svg" alt=" "><!----><span class="vp-site-name hide-in-pad"> </span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="ğŸ”§ å·¥å…·"><span class="title"><!---->ğŸ”§ å·¥å…·</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>æ–‡æ¡£</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a aria-label="Markdown" class="vp-link nav-link nav-link" href="/Tools/MarkDown.html"><!---->Markdown<!----></a></li><li class="dropdown-subitem"><a aria-label="èµ„æºæ•´åˆ" class="vp-link nav-link nav-link" href="/Tools/Resource.html"><!---->èµ„æºæ•´åˆ<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>å·¥å…·</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a aria-label="Git" class="vp-link nav-link nav-link" href="/Tools/Git.html"><!---->Git<!----></a></li></ul></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="  ğŸ“‘ ç å¤´"><span class="title"><!---->  ğŸ“‘ ç å¤´</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="è§†é¢‘ç†è§£" class="vp-link nav-link nav-link" href="/keyan/videoUnderstanding/videoUnderstanding.html"><!---->è§†é¢‘ç†è§£<!----></a></li><li class="dropdown-item"><a aria-label="è§†é¢‘è¡¨å¾" class="vp-link nav-link nav-link" href="/keyan/videoRepresentation/videoRepresentation.html"><!---->è§†é¢‘è¡¨å¾<!----></a></li><li class="dropdown-item"><a aria-label="è§†é¢‘å¯¹è¯" class="vp-link nav-link nav-link" href="/keyan/videoDialog/videoDialog.html"><!---->è§†é¢‘å¯¹è¯<!----></a></li><li class="dropdown-item"><a aria-label="å¯¹æ¯”å­¦ä¹ " class="vp-link nav-link nav-link" href="/keyan/contrastiveLearning/contrastiveLearning.html"><!---->å¯¹æ¯”å­¦ä¹ <!----></a></li><li class="dropdown-item"><a aria-label="å¤šæ¨¡æ€" class="vp-link nav-link nav-link" href="/keyan/multiModal/multiModal.html"><!---->å¤šæ¨¡æ€<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="  ğŸ§« ç‚‰"><span class="title"><!---->  ğŸ§« ç‚‰</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="å•æœºå¤šå¡DDP" class="vp-link nav-link nav-link" href="/train/DDP/DDP.html"><!---->å•æœºå¤šå¡DDP<!----></a></li><li class="dropdown-item"><a aria-label="AVSD" class="vp-link nav-link nav-link" href="/train/AVSD/AVSD.html"><!---->AVSD<!----></a></li><li class="dropdown-item"><a aria-label="å¥‡æ·«æŠ€å·§" class="vp-link nav-link nav-link" href="/train/trick/trick.html"><!---->å¥‡æ·«æŠ€å·§<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="  ğŸ“– é“å¿ƒ"><span class="title"><!---->  ğŸ“– é“å¿ƒ</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="2023å¹´9æœˆ" class="vp-link nav-link nav-link" href="/book/202309.html"><!---->2023å¹´9æœˆ<!----></a></li><li class="dropdown-item"><a aria-label="2023å¹´10æœˆ" class="vp-link nav-link nav-link" href="/book/202310.html"><!---->2023å¹´10æœˆ<!----></a></li><li class="dropdown-item"><a aria-label="2023å¹´11æœˆ" class="vp-link nav-link nav-link" href="/book/202311.html"><!---->2023å¹´11æœˆ<!----></a></li><li class="dropdown-item"><a aria-label="æ¯›æ³½ä¸œé€‰é›†" class="vp-link nav-link nav-link" href="/book/maoxuan.html"><!---->æ¯›æ³½ä¸œé€‰é›†<!----></a></li></ul></button></div></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><!----><div class="nav-item hide-in-mobile"><button type="button" class="outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="outlook-dropdown"><!----></div></button></div><!----><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><!--[--><a aria-label="è§†é¢‘ç†è§£ç»¼è¿°æ€§è´¨çš„è®°å½•" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/videoUnderstanding/videoUnderstanding.html"><!---->è§†é¢‘ç†è§£ç»¼è¿°æ€§è´¨çš„è®°å½•<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="å…³äºè§†é¢‘ç†è§£çš„è®ºæ–‡æ”¶é›†(è¾ƒæ–°)" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/videoRepresentation/videoRepresentation.html"><!---->å…³äºè§†é¢‘ç†è§£çš„è®ºæ–‡æ”¶é›†(è¾ƒæ–°)<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="è§†é¢‘å¯¹è¯æ–¹å‘å¤§è®ºæ–‡æ€§è´¨çš„è®°å½•" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/videoDialog/videoDialog.html"><!---->è§†é¢‘å¯¹è¯æ–¹å‘å¤§è®ºæ–‡æ€§è´¨çš„è®°å½•<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="å¯¹æ¯”å­¦ä¹ ç»¼è¿°æ€§è´¨çš„è®°å½•" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/contrastiveLearning/contrastiveLearning.html"><!---->å¯¹æ¯”å­¦ä¹ ç»¼è¿°æ€§è´¨çš„è®°å½•<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="å¤šæ¨¡æ€æ–¹å‘ç»¼è¿°æ€§è´¨çš„è®°å½•" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/multiModal/multiModal.html"><!---->å¤šæ¨¡æ€æ–¹å‘ç»¼è¿°æ€§è´¨çš„è®°å½•<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†</h1><div class="page-info"><span class="page-author-info" aria-label="ä½œè€…ğŸ–Š" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/WillebrordSnell" target="_blank" rel="noopener noreferrer">Mr.R</a></span><span property="author" content="Mr.R"></span></span><!----><span class="page-date-info" aria-label="å†™ä½œæ—¥æœŸğŸ“…" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-09-19T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="é˜…è¯»æ—¶é—´âŒ›" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>å¤§çº¦ 20 åˆ†é’Ÿ</span><meta property="timeRequired" content="PT20M"></span><span class="page-category-info" aria-label="åˆ†ç±»ğŸŒˆ" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category3 clickable" role="navigation">ç§‘ç ”</span><!--]--><meta property="articleSection" content="ç§‘ç ”"></span><span class="page-tag-info" aria-label="æ ‡ç­¾ğŸ·" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag1 clickable" role="navigation">å»ç å¤´æ•´ç‚¹è®ºæ–‡</span><!--]--><meta property="keywords" content="å»ç å¤´æ•´ç‚¹è®ºæ–‡"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">æ­¤é¡µå†…å®¹<button type="button" class="print-button" title="æ‰“å°"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#eccv">ECCV</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2022-eccv">2022 ECCV</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2020-eccv">2020 ECCV</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#iccv">ICCV</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2021-iccv">2021 ICCV</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2019-iccv">2019 ICCV</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#cvpr">CVPR</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2023-cvpr">2023 CVPR</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2022-cvpr">2022 CVPR</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2021-cvpr">2021 CVPR</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2020-cvpr">2020 CVPR</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2019-cvpr">2019 CVPR</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#aaai">AAAI</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2023-aaai">2023 AAAI</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2022-aaai">2022 AAAI</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2021-aaai">2021 AAAI</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2020-aaai">2020 AAAI</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2019-aaai">2019 AAAI</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#emnlp">EMNLP</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2023-emnlp">2023 EMNLP</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2022-emnlp">2022 EMNLP</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2021-emnlp">2021 EMNLP</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2020-emnlp">2020 EMNLP</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2019-emnlp">2019 EMNLP</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#acl">ACL</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2023-acl">2023 ACL</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2022-acl">2022 ACL</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2021-acl">2021 ACL</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2020-acl">2020 ACL</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#_2019-acl">2019 ACL</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><h1 id="ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†" tabindex="-1"><a class="header-anchor" href="#ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†" aria-hidden="true">#</a> ä¸€äº›å…³äºdialogæ–¹å‘çš„è®ºæ–‡æ”¶é›†</h1><p>æœ¬æ–‡ä¸»è¦è®°å½•ä¸€ä¸‹è¿‘4å¹´(2019å¹´èµ·)å„é¡¶ä¼šé¡¶åˆŠæœ‰å…³dialogçš„paperåå­—ï¼Œä»¥ä¾¿åç»­video dialogå·¥ä½œçš„è°ƒç ”å’Œå±•å¼€<br> (æœ¬æ–‡æ¡£æœªç»è¿‡ä»»ä½•ç­›é€‰ï¼Œä»…é€šè¿‡å…³é”®è¯æœç´¢å¾—åˆ°paperåå­—)<br> æ¨èäºŒçº§æ£€ç´¢å…³é”®è¯ï¼šhistory ã€ generaã€ visualã€ Supervisã€ videoç­‰</p><h2 id="eccv" tabindex="-1"><a class="header-anchor" href="#eccv" aria-hidden="true">#</a> ECCV</h2><h3 id="_2022-eccv" tabindex="-1"><a class="header-anchor" href="#_2022-eccv" aria-hidden="true">#</a> 2022 ECCV</h3><p>New Datasets and Models for Contextual Reasoning in Visual Dialog<br> Video Dialog as Conversation About Objects Living in Space-Time</p><h3 id="_2020-eccv" tabindex="-1"><a class="header-anchor" href="#_2020-eccv" aria-hidden="true">#</a> 2020 ECCV</h3><p>Efficient Attention Mechanism for Visual Dialog that Can Handle All the Interactions Between Multiple Inputs<br> Describing Unseen Videos via Multi-modal Cooperative Dialog Agents<br> Large-Scale Pretraining for Visual Dialog: A Simple State-of-the-Art Baseline<br> Guessing State Tracking for Visual Dialogue</p><h2 id="iccv" tabindex="-1"><a class="header-anchor" href="#iccv" aria-hidden="true">#</a> ICCV</h2><h3 id="_2021-iccv" tabindex="-1"><a class="header-anchor" href="#_2021-iccv" aria-hidden="true">#</a> 2021 ICCV</h3><p>Self-Motivated Communication Agent for Real-World Vision-Dialog Navigation<br> Unified Questioner Transformer for Descriptive Question Generation in Goal-Oriented Visual Dialogue<br> On the hidden treasure of dialog in video question answering<br> Talk-to-Edit: Fine-Grained Facial Editing via Dialog</p><h3 id="_2019-iccv" tabindex="-1"><a class="header-anchor" href="#_2019-iccv" aria-hidden="true">#</a> 2019 ICCV</h3><p>Making History Matter: History-Advantage Sequence Training for Visual Dialog</p><h2 id="cvpr" tabindex="-1"><a class="header-anchor" href="#cvpr" aria-hidden="true">#</a> CVPR</h2><h3 id="_2023-cvpr" tabindex="-1"><a class="header-anchor" href="#_2023-cvpr" aria-hidden="true">#</a> 2023 CVPR</h3><p>The Dialog Must Go On: Improving Visual Dialog via Generative Self-Training</p><h3 id="_2022-cvpr" tabindex="-1"><a class="header-anchor" href="#_2022-cvpr" aria-hidden="true">#</a> 2022 CVPR</h3><p>UTC: A Unified Transformer with Inter-Task Contrastive Learning for Visual Dialog</p><h3 id="_2021-cvpr" tabindex="-1"><a class="header-anchor" href="#_2021-cvpr" aria-hidden="true">#</a> 2021 CVPR</h3><p>Learning Better Visual Dialog Agents With Pretrained Visual-Linguistic Representation</p><h3 id="_2020-cvpr" tabindex="-1"><a class="header-anchor" href="#_2020-cvpr" aria-hidden="true">#</a> 2020 CVPR</h3><p>Iterative Context-Aware Graph Inference for Visual Dialog<br> Vision-Dialog Navigation by Exploring Cross-Modal Memory<br> Two Causal Principles for Improving Visual Dialog</p><h3 id="_2019-cvpr" tabindex="-1"><a class="header-anchor" href="#_2019-cvpr" aria-hidden="true">#</a> 2019 CVPR</h3><p>Reasoning Visual Dialogs With Structural and Partial Observations<br> Recursive Visual Attention in Visual Dialog<br> Audio Visual Scene-Aware Dialog<br> Image-Question-Answer Synergistic Network for Visual Dialog<br> A Simple Baseline for Audio-Visual Scene-Aware Dialog</p><h2 id="aaai" tabindex="-1"><a class="header-anchor" href="#aaai" aria-hidden="true">#</a> AAAI</h2><h3 id="_2023-aaai" tabindex="-1"><a class="header-anchor" href="#_2023-aaai" aria-hidden="true">#</a> 2023 AAAI</h3><p>Learning to Memorize Entailment and Discourse Relations for Persona-Consistent Dialogues<br> Learning towards Selective Data Augmentation for Dialogue Generation<br> Learning to Imagine: Distillation-Based Interactive Context Exploitation for Dialogue State Tracking<br> Personalized Dialogue Generation with Persona-Adaptive Attention<br> Explaining (Sarcastic) Utterances to Enhance Affect Understanding in Multimodal Dialogues<br> Mitigating Negative Style Transfer in Hybrid Dialogue System<br> Heterogeneous-Branch Collaborative Learning for Dialogue Generation<br> Learning to Know Myself: A Coarse-to-Fine Persona-Aware Training Framework for Personalized Dialogue Generation<br> A Disentangled-Attention Based Framework with Persona-Aware Prompt Learning for Dialogue Generation<br> Towards Credible Human Evaluation of Open-Domain Dialog Systems Using Interactive Setup<br> Towards Complex Scenarios: Building End-to-End Task-Oriented Dialogue System across Multiple Knowledge Bases<br> Towards Diverse, Relevant and Coherent Open-Domain Dialogue Generation via Hybrid Latent Variables<br> Taming Continuous Posteriors for Latent Variational Dialogue Policies<br> Dialogue Rewriting via Skeleton-Guided Generation<br> Dialogue State Distillation Network with Inter-slot Contrastive Learning for Dialogue State Tracking<br> Balanced Meta Learning and Diverse Sampling for Lifelong Task-Oriented Dialogue Systems<br> On the Calibration and Uncertainty with PÃ³lya-Gamma Augmentation for Dialog Retrieval Models<br> Multi-Action Dialog Policy Learning from Logged User Feedback<br> KPT: Keyword-Guided Pre-training for Grounded Dialog Generation<br> Help Me Heal: A Reinforced Polite and Empathetic Mental Health and Legal Counseling Dialogue System for Crime Victims<br> Improving Dialogue Intent Classification with a Knowledge-Enhanced Multifactor Graph Model (Student Abstract)<br> Class Incremental Learning for Task-Oriented Dialogue System with Contrastive Distillation on Internal Representations (Student Abstract)</p><h3 id="_2022-aaai" tabindex="-1"><a class="header-anchor" href="#_2022-aaai" aria-hidden="true">#</a> 2022 AAAI</h3><p>ALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with Semi-supervised Learning and Explicit Policy Injection<br> Dual Task Framework for Improving Persona-Grounded Dialogue Dataset<br> SGD-X: A Benchmark for Robust Generalization in Schema-Guided Dialogue Systems<br> Knowledge Bridging for Empathetic Dialogue Generation<br> Contrast and Generation Make BART a Good Dialogue Emotion Recognizer<br> A Semi-supervised Learning Approach with Two Teachers to Improve Breakdown Identification in Dialogues<br> Semantic Parsing in Task-Oriented Dialog with Recursive Insertion-Based Encoder<br> CINS: Comprehensive Instruction for Few-Shot Learning in Task-Oriented Dialog Systems<br> GraphMemDialog: Optimizing End-to-End Task-Oriented Dialog Systems Using Graph Memory Networks<br> ValueNet: A New Dataset for Human Value Driven Dialogue System<br> Fusing Task-Oriented and Open-Domain Dialogues in Conversational Agents<br> MDD-Eval: Self-Training on Augmented Data for Multi-Domain Dialogue Evaluation<br> Efficient Dialog Policy Learning by Reasoning with Contextual Knowledge<br> DialogLM: Pre-trained Model for Long Dialogue Understanding and Summarization<br> Multi-Dimension Attention for Multi-Turn Dialog Generation (Student Abstract)<br> Building Goal-Oriented Dialogue Systems with Situated Visual Context</p><h3 id="_2021-aaai" tabindex="-1"><a class="header-anchor" href="#_2021-aaai" aria-hidden="true">#</a> 2021 AAAI</h3><p>Dynamic Graph Representation Learning for Video Dialog via Multi-Modal Shuffled Transformers<br> Structured Co-reference Graph Attention for Video-grounded Dialogue<br> Reasoning in Dialog: Improving Response Generation by Context Reading Comprehension<br> MultiTalk: A Highly-Branching Dialog Testbed for Diverse Conversations<br> Multi-View Feature Representation for Dialogue Generation with Bidirectional Distillation<br> DialogBERT: Discourse-Aware Response Generation via Learning to Recover and Rank Utterances<br> DDRel: A New Dataset for Interpersonal Relation Classification in Dyadic Dialogues<br> Interpretable NLG for Task-oriented Dialogue Systems with Heterogeneous Rendering Machines<br> Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation<br> Converse, Focus and Guess - Towards Multi-Document Driven Dialogue<br> Filling the Gap of Utterance-aware and Speaker-aware Representation for Multi-turn Dialogue<br> Dialog Policy Learning for Joint Clarification and Active Learning Queries<br> A Student-Teacher Architecture for Dialog Domain Adaptation Under the Meta-Learning Setting<br> Exploring Auxiliary Reasoning Tasks for Task-oriented Dialog Systems with Meta Cooperative Learning<br> Co-GAT: A Co-Interactive Graph Attention Network for Joint Dialog Act Recognition and Sentiment Classification<br> DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition<br> Unsupervised Learning of Deterministic Dialogue Structure with Edge-Enhanced Graph Auto-Encoder<br> NaturalConv: A Chinese Dialogue Dataset Towards Multi-turn Topic-driven Conversation<br> Learning an Effective Context-Response Matching Model with Self-Supervised Tasks for Retrieval-based Dialogues<br> Topic-Aware Multi-turn Dialogue Modeling<br> UBAR: Towards Fully End-to-End Task-Oriented Dialog System with GPT-2<br> Open Domain Dialogue Generation with Latent Images<br> Unsupervised Abstractive Dialogue Summarization for Tete-a-Tetes<br> Automatic Curriculum Learning With Over-repetition Penalty for Dialogue Policy Learning<br> Stylized Dialogue Response Generation Using Stylized Unpaired Texts<br> Topic-Oriented Spoken Dialogue Summarization for Customer Service with Saliency-Aware Topic Modeling<br> Lifelong and Continual Learning Dialogue Systems: Learning during Conversation<br> Empowering Conversational AI is a Trip to Mars: Progress and Future of Open Domain Human-Computer Dialogues<br> Knowledge-aware Dialogue Generation with Hybrid Attention (Student Abstract)<br> Bootstrapping Dialog Models from Human to Human Conversation Logs<br> Dialog Router: Automated Dialog Transition via Multi-Task Learning<br> Integrating Pre-trained Model into Rule-based Dialogue Management</p><h3 id="_2020-aaai" tabindex="-1"><a class="header-anchor" href="#_2020-aaai" aria-hidden="true">#</a> 2020 AAAI</h3><p>Towards Hands-Free Visual Dialog Interactive Recommendation<br> Modeling Dialogues with Hashcode Representations: A Nonparametric Approach<br> Learning from Easy to Complex: Adaptive Multi-Curricula Learning for Neural Dialogue Generation<br> DMRM: A Dual-Channel Multi-Hop Reasoning Model for Visual Dialog<br> Schema-Guided Multi-Domain Dialogue State Tracking with Graph Attention Neural Networks<br> Guiding Attention in Sequence-to-Sequence Models for Dialogue Act Prediction<br> Likelihood Ratios and Generative Classifiers for Unsupervised Out-of-Domain Detection in Task Oriented Dialog<br> Predictive Engagement: An Efficient Metric for Automatic Evaluation of Open-Domain Dialogue Systems<br> MALA: Cross-Domain Dialogue Generation with Action Learning<br> Bayes-Adaptive Monte-Carlo Planning and Learning for Goal-Oriented Dialogues<br> Modality-Balanced Models for Visual Dialogue<br> MA-DST: Multi-Attention-Based Scalable Dialog State Tracking<br> ALOHA: Artificial Learning of Human Attributes for Dialogue Agents<br> End-to-End Trainable Non-Collaborative Dialog System<br> MOSS: End-to-End Dialog System Framework with Modular Supervision<br> Attention-Informed Mixed-Language Training for Zero-Shot Cross-Lingual Task-Oriented Dialogue Systems<br> MTSS: Learn from Multiple Domain Teachers and Become a Multi-Domain Dialogue Expert<br> DCR-Net: A Deep Co-Interactive Relation Network for Joint Dialog Act Recognition and Sentiment Classification<br> Entrainment2Vec: Embedding Entrainment for Multi-Party Dialogues<br> Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided Dialogue Dataset<br> Hierarchical Reinforcement Learning for Open-Domain Dialog<br> Generating Persona Consistent Dialogues by Exploiting Natural Language Inference<br> History-Adaption Knowledge Incorporation Mechanism for Multi-Turn Dialogue System<br> Improving Knowledge-Aware Dialogue Generation via Knowledge Base Question Answering<br> Sentiment Classification in Customer Service Dialogue with Topic-Aware Multi-Task Learning<br> Masking Orchestration: Multi-Task Pretraining for Multi-Role Dialogue Representation Learning<br> Dialog State Tracking with Reinforced Data Augmentation<br> Filling Conversation Ellipsis for Better Social Dialog Understanding<br> Task-Oriented Dialog Systems That Consider Multiple Appropriate Responses under the Same Context<br> A Pre-Training Based Personalized Dialogue Generation Model with Persona-Sparse Data<br> DualVD: An Adaptive Dual Encoding Model for Deep Visual Understanding in Visual Dialogue<br> Visual Dialogue State Tracking for Question Generation<br> Multi-Speaker Video Dialog with Frame-Level Temporal Localization<br> Back to the Future for Dialogue Research<br> Doc2Dial: A Framework for Dialogue Composition Grounded in Documents<br> Automatic Text-Based Personality Recognition on Monologues and Multiparty Dialogues Using Attentive Networks and Contextual Embeddings (Student Abstract)<br> Topic Enhanced Controllable CVAE for Dialogue Generation (Student Abstract)<br> Breakdown Detection in Negotiation Dialogues (Student Abstract)</p><h3 id="_2019-aaai" tabindex="-1"><a class="header-anchor" href="#_2019-aaai" aria-hidden="true">#</a> 2019 AAAI</h3><p>Goal-Oriented Dialogue Policy Learning from Failures<br> Re-Evaluating ADEM: A Deeper Look at Scoring Dialogue Responses<br> Dialogue Generation: From Imitation Learning to Inverse Reinforcement Learning<br> Learning Personalized End-to-End Goal-Oriented Dialog<br> DialogueRNN: An Attentive RNN for Emotion Detection in Conversations<br> A Deep Sequential Model for Discourse Parsing on Multi-Party Dialogues<br> Switch-Based Active Deep Dyna-Q: Efficient Adaptive Planning for Task-Completion Dialogue Policy Learning<br> End-to-End Knowledge-Routed Relational Dialogue System for Automatic Diagnosis<br> MAi: An Intelligent Model Acquisition Interface for Interactive Specification of Dialogue Agents<br> Reinforcement Learning for Improved Low Resource Dialogue Generation</p><h2 id="emnlp" tabindex="-1"><a class="header-anchor" href="#emnlp" aria-hidden="true">#</a> EMNLP</h2><h3 id="_2023-emnlp" tabindex="-1"><a class="header-anchor" href="#_2023-emnlp" aria-hidden="true">#</a> 2023 EMNLP</h3><h3 id="_2022-emnlp" tabindex="-1"><a class="header-anchor" href="#_2022-emnlp" aria-hidden="true">#</a> 2022 EMNLP</h3><p>BotSIM: An End-to-End Bot Simulation Framework for Commercial Task-Oriented Dialog Systems<br> InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning<br> Correctable-DST: Mitigating Historical Context Mismatch between Training and Inference for Improved Dialogue State Tracking<br> Curriculum Prompt Learning with Self-Training for Abstractive Dialogue Summarization<br> MetaASSIST: Robust Dialogue State Tracking with Meta Learning<br> Counterfactual Data Augmentation via Perspective Transition for Open-Domain Dialogues<br> There Is No Standard Answer: Knowledge-Grounded Dialogue Generation with Adversarial Activated Multi-Reference Learning<br> D4: a Chinese Dialogue Dataset for Depression-Diagnosis-Oriented Chat<br> Exploiting domain-slot related keywords description for Few-Shot Cross-Domain Dialogue State Tracking<br> Navigating Connected Memories with a Task-oriented Dialog System<br> Back to the Future: Bidirectional Information Decoupling Network for Multi-turn Dialogue Modeling<br> Improving Multi-turn Emotional Support Dialogue Generation with Lookahead Strategy Planning<br> Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems<br> FineD-Eval: Fine-grained Automatic Dialogue-Level Evaluation<br> ProsocialDialog: A Prosocial Backbone for Conversational Agents<br> CGoDial: A Large-Scale Benchmark for Chinese Goal-oriented Dialog Evaluation<br> Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue<br> A Speaker-Aware Co-Attention Framework for Medical Dialogue Information Extraction<br> Analyzing and Evaluating Faithfulness in Dialogue Summarization<br> STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension<br> BotsTalk: Machine-sourced Framework for Automatic Curation of Large-scale Multi-skill Dialogue Datasets<br> Q-TOD: A Query-driven Task-oriented Dialogue System<br> Dial2vec: Self-Guided Contrastive Learning of Unsupervised Dialogue Embeddings<br> Extending Phrase Grounding with Pronouns in Visual Dialogues<br> ClidSum: A Benchmark Dataset for Cross-Lingual Dialogue Summarization<br> Human-Machine Collaboration Approaches to Build a Dialogue Dataset for Hate Speech Countering<br> Don&#39;t Copy the Teacher: Data and Model Challenges in Embodied Dialogue<br> Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence<br> Towards Efficient Dialogue Pre-training with Transferable and Interpretable Latent Structure<br> Reflect, Not Reflex: Inference-Based Common Ground Improves Dialogue Response Quality<br> FlowEval: A Consensus-Based Dialogue Evaluation Framework Using Segment Act Flows<br> Pneg: Prompt-based Negative Response Generation for Dialogue Response Selection Task<br> Structural Constraints and Natural Language Inference for End-to-End Flowchart Grounded Dialog Response Generation<br> FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue<br> IMâŒƒ2: an Interpretable and Multi-category Integrated Metric Framework for Automatic Dialogue Evaluation<br> Prompt Conditioned VAE: Enhancing Generative Replay for Lifelong Learning in Task-Oriented Dialogue<br> End-to-End Neural Discourse Deixis Resolution in Dialogue<br> CDialog: A Multi-turn Covid-19 Conversation Dataset for Entity-Aware Dialog Generation<br> Injecting Domain Knowledge in Language Models for Task-oriented Dialogue Systems<br> JDDC 2.1: A Multimodal Chinese Dialogue Dataset with Joint Tasks of Query Rewriting, Response Generation, Discourse Parsing, and Summarization<br> DialogConv: A Lightweight Fully Convolutional Network for Multi-view Response Selection</p><h3 id="_2021-emnlp" tabindex="-1"><a class="header-anchor" href="#_2021-emnlp" aria-hidden="true">#</a> 2021 EMNLP</h3><p>Athena 2.0: Contextualized Dialogue Management for an Alexa Prize SocialBot<br> Towards Making the Most of Dialogue Characteristics for Neural Chat Translation<br> Low-Resource Dialogue Summarization with Domain-Agnostic Multi-Source Pretraining<br> Controllable Neural Dialogue Summarization with Personal Named Entity Planning<br> GOLD: Improving Out-of-Scope Detection in Dialogues using Data Augmentation<br> Graph Based Network with Contextualized Representations of Turns in Dialogue<br> Automatically Exposing Problems with Neural Dialog Models<br> MindCraft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks<br> Cross-lingual Intermediate Fine-tuning improves Dialogue State Tracking<br> We&#39;ve had this conversation before: A Novel Approach to Measuring Dialog Similarity<br> CR-Walker: Tree-Structured Graph Reasoning and Dialog Acts for Conversational Recommendation<br> DIALKI: Knowledge Identification in Conversational Systems through Dialogue-Document Contextualization<br> Self-training Improves Pre-training for Few-shot Learning in Task-oriented Dialog Systems<br> Contextual Rephrase Detection for Reducing Friction in Dialogue Systems<br> Reference-Centric Models for Grounded Collaborative Dialogue<br> Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path Grounding<br> Thinking Clearly, Talking Fast: Concept-Guided Non-Autoregressive Generation for Open-Domain Dialogue Systems<br> Generation and Extraction Combined Dialogue State Tracking with Hierarchical Ontology Integration<br> CoLV: A Collaborative Latent Variable Model for Knowledge-Grounded Dialogue Generation<br> A Three-Stage Learning Framework for Low-Resource Knowledge-Grounded Dialogue Generation<br> Intention Reasoning Network for Multi-Domain End-to-end Task-Oriented Dialogue<br> More is Better: Enhancing Open-Domain Dialogue Generation via Multi-Source Heterogeneous Knowledge<br> Domain-Lifelong Learning for Dialogue State Tracking via Knowledge Preservation Networks<br> Different Strokes for Different Folks: Investigating Appropriate Further Pre-training Approaches for Diverse Dialogue Tasks<br> Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation<br> Don&#39;t be Contradicted with Anything! CI-ToD: Towards Benchmarking Consistency for Task-oriented Dialogue System<br> Transferable Persona-Grounded Dialogues via Grounded Minimal Edits<br> DialogueCSE: Dialogue-based Contrastive Learning of Sentence Embeddings<br> Adaptive Bridge between Training and Inference for Dialogue Generation<br> Smoothing Dialogue States for Open Conversational Machine Reading<br> Exophoric Pronoun Resolution in Dialogues with Topic Regularization<br> Contextualize Knowledge Bases with Transformer for End-to-end Task-Oriented Dialogue Systems<br> Efficient Dialogue Complementary Policy Learning via Deep Q-network Policy and Episodic Memory Policy<br> End-to-End Learning of Flowchart Grounded Task-Oriented Dialogs<br> CSDS: A Fine-Grained Chinese Dataset for Customer Service Dialogue Summarization<br> Building and Evaluating Open-Domain Dialogue Corpora with Clarifying Questions<br> Region under Discussion for visual dialog<br> Just Say No: Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts<br> Multi-Modal Open-Domain Dialogue<br> Zero-Shot Dialogue Disentanglement by Self-Supervised Entangled Response Selection<br> SIMMC 2.0: A Task-oriented Dialog Dataset for Immersive Multimodal Conversations<br> RAST: Domain-Robust Dialogue Rewriting as Sequence Tagging<br> MRF-Chat: Improving Dialogue with Markov Random Fields<br> Dialogue State Tracking with a Language Model using Schema-Driven Prompting<br> MultiDoc2Dial: Modeling Dialogues Grounded in Multiple Documents<br> NDH-Full: Learning and Evaluating Navigational Agents on Full-Length Dialogue<br> Simple Conversational Data Augmentation for Semi-supervised Abstractive Dialogue Summarization<br> Towards Automatic Evaluation of Dialog Systems: A Model-Free Off-Policy Evaluation Approach<br> Continual Learning in Task-Oriented Dialogue Systems<br> Investigating Robustness of Dialog Models to Popular Figurative Language Constructs<br> Effective Sequence-to-Sequence Dialogue State Tracking<br> Learning Neural Templates for Recommender Dialogue System<br> Proxy Indicators for the Quality of Open-domain Dialogues<br><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Q</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">Q^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>: Evaluating Factual Consistency in Knowledge-Grounded Dialogues via Question Generation and Question Answering<br> Knowledge-Aware Graph-Enhanced GPT-2 for Dialogue State Tracking<br> A Collaborative Multi-agent Reinforcement Learning Framework for Dialog Action Decomposition<br> Zero-Shot Dialogue State Tracking via Cross-Task Transfer<br> Uncertainty Measures in Neural Belief Tracking and the Effects on Dialogue Policy Performance<br> A Bag of Tricks for Dialogue Summarization<br> Is Information Density Uniform in Task-Oriented Dialogues<br> Code-switched inspired losses for spoken dialog representations<br> Looking for Confirmations: An Effective and Human-Like Visual Dialogue Strategy</p><h3 id="_2020-emnlp" tabindex="-1"><a class="header-anchor" href="#_2020-emnlp" aria-hidden="true">#</a> 2020 EMNLP</h3><p>Dialogue Response Ranking Training with Large-Scale Human Feedback Data<br> Where Are You? Localization from Embodied Dialog<br> Mitigating Gender Bias for Neural Dialogue Generation with Adversarial Learning<br> Will I Sound Like Me? Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness<br> TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue<br> RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling<br> Filtering Noisy Dialogue Corpora by Connectivity and Content Relatedness<br> BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues<br> UniConv: A Unified Conversational Neural Architecture for Multi-domain Task-oriented Dialogues<br> GraphDialog: Integrating Graph Knowledge into End-to-End Task-Oriented Dialogue Systems<br> Structured Attention for Unsupervised Dialogue Structure Induction<br> Cross Copy Network for Dialogue Generation<br> Multi-turn Response Selection using Dialogue Dependency Relations<br> Parallel Interactive Networks for Multi-Domain Dialogue State Generation<br> How to Make Neural Natural Language Generation as Reliable as Templates in Task-Oriented Dialogue<br> Slot Attention with Value Normalization for Multi-Domain Dialogue State Tracking<br> A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses<br> VD-BERT: A Unified Vision and Dialog Transformer with BERT<br> Knowledge-Grounded Dialogue Generation with Pre-trained Language Models<br> MinTL: Minimalist Transfer Learning for Task-Oriented Dialogue Systems<br> Variational Hierarchical Dialog Autoencoder for Dialog State Tracking Data Augmentation<br> Bridging the Gap between Prior and Posterior Knowledge Selection for Knowledge-Grounded Dialogue Generation<br> Counterfactual Off-Policy Training for Neural Dialogue Generation<br> Dialogue Distillation: Open-Domain Dialogue Augmentation Using Unpaired Data<br> Task-Completion Dialogue Policy Learning via Monte Carlo Tree Search with Dueling Network<br> AttnIO: Knowledge Graph Exploration with In-and-Out Attention Flow for Knowledge-Grounded Dialogue<br> Amalgamating Knowledge from Two Teachers for Task-oriented Dialogue System with Adversarial Training<br> Spot The Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems<br> Human-centric dialog training via offline reinforcement learning<br> Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization<br> Generating Dialogue Responses from a Semantic Latent Space<br> Probing Task-Oriented Dialogue Representation from Language Models<br> Simple Data Augmentation with the Mask Token Improves Domain Adaptation for Dialog Act Tagging<br> Sound Natural: Content Rephrasing in Dialog Systems<br> Template Guided Text Generation for Task-Oriented Dialogue<br> Regularizing Dialogue Generation by Imitating Implicit Scenarios<br> Semantic Role Labeling Guided Multi-turn Dialogue ReWriter<br> Profile Consistency Identification for Open-domain Dialogue Agents<br> Conversational Semantic Parsing for Dialog State Tracking<br> doc2dial: A Goal-Oriented Document-Grounded Dialogue Dataset<br> Interview: Large-scale Modeling of Media Dialog with Discourse Patterns and Knowledge Grounding<br> INSPIRED: Toward Sociable Recommendation Dialog Systems<br> Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation<br> Like hiking? You probably enjoy nature: Persona-grounded Dialog with Commonsense Expansions<br> A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning<br> The World is Not Binary: Learning to Rank with Grayscale Data for Dialogue Response Selection<br> GRADE: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems<br> MedDialog: Large-scale Medical Dialogue Datasets</p><h3 id="_2019-emnlp" tabindex="-1"><a class="header-anchor" href="#_2019-emnlp" aria-hidden="true">#</a> 2019 EMNLP</h3><p>LIDA: Lightweight Interactive Dialogue Annotator<br> PolyResponse: A Rank-based Approach to Task-Oriented Dialogue with Application in Restaurant Search and Booking<br> PyOpenDial: A Python-based Domain-Independent Toolkit for Developing Spoken Dialogue Systems with Probabilistic Rules<br> Guided Dialog Policy Learning: Reward Estimation for Multi-Domain Task-Oriented Dialog<br> Entity-Consistent End-to-end Task-Oriented Dialogue System with KB Retriever<br> Building Task-Oriented Visual Dialog Systems Through Alternative Optimization Between Dialog Policy and Language Generation<br> DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation<br> Using Customer Service Dialogues for Satisfaction Analysis with Context-Assisted Multiple Instance Learning<br> Multi-task Learning for Natural Language Generation in Task-Oriented Dialogue<br> Dirichlet Latent Variable Hierarchical Recurrent Encoder-Decoder in Dialogue Generation<br> Semi-Supervised Bootstrapping of Dialogue State Trackers for Task-Oriented Modelling<br> Sampling Matters! An Empirical Study of Negative Sampling Strategies for Learning of Matching Models in Retrieval-based Dialogue Systems<br> Zero-shot Cross-lingual Dialogue Systems with Transferable Latent Variables<br> Modeling Multi-Action Policy for Task-Oriented Dialogues<br> Automatically Learning Data Augmentation Policies for Dialogue Tasks<br> Improving Generative Visual Dialog by Answering Diverse Questions<br> Dependency Parsing for Spoken Dialog Systems<br> Span-based Hierarchical Semantic Parsing for Task-Oriented Dialog<br> Data-Efficient Goal-Oriented Conversation with Dialogue Knowledge Transfer Networks<br> Multi-Granularity Representations of Dialog<br> Are You for Real? Detecting Identity Fraud via Dialogue Interactions<br> Adaptive Parameterization for Neural Dialogue Generation<br> Towards Knowledge-Based Recommender Dialog System<br> Improving Open-Domain Dialogue Systems via Multi-Turn Incomplete Utterance Restoration<br> DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic Knowledge Graphs<br> Retrieval-guided Dialogue Response Generation via a Matching-to-Generation Framework<br> Scalable and Accurate Dialogue State Tracking via Hierarchical Sequence Generation<br> A Semi-Supervised Stable Variational Network for Promoting Replier-Consistency in Dialogue Generation<br> Recommendation as a Communication Game: Self-Supervised Bot-Play for Goal-oriented Dialogue<br> A Practical Dialogue-Act-Driven Conversation Model for Multi-Turn Response Selection<br> How to Build User Simulators to Train RL-based Dialog Systems<br> Dual Attention Networks for Visual Reference Resolution in Visual Dialog<br> Video Dialog via Progressive Inference and Cross-Transformer<br> Dialog Intent Induction with Deep Multi-View Clustering<br> Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset<br> Multi-Domain Goal-Oriented Dialogues (MultiDoGO): Strategies toward Curating and Annotating Large Scale Dialogue Data<br> Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack<br> GECOR: An End-to-End Generative Ellipsis and Co-reference Resolution Model for Task-Oriented Dialogue<br> Enhancing Dialogue Symptom Diagnosis with Global Attention and Symptom Graph<br> What You See is What You Get: Visual Pronoun Coreference Resolution in Dialogues</p><h2 id="acl" tabindex="-1"><a class="header-anchor" href="#acl" aria-hidden="true">#</a> ACL</h2><h3 id="_2023-acl" tabindex="-1"><a class="header-anchor" href="#_2023-acl" aria-hidden="true">#</a> 2023 ACL</h3><p>ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?<br> Controllable Mixed-Initiative Dialogue Generation through Prompting<br> Towards Fewer Hallucinations in Knowledge-Grounded Dialogue Generation via Augmentative and Contrastive Knowledge-Dialogue<br> One Cannot Stand for Everyone! Leveraging Multiple User Simulators to train Task-oriented Dialogue Systems<br> Span-Selective Linear Attention Transformers for Effective and Robust Schema-Guided Dialogue State Tracking<br> EM Pre-training for Multi-party Dialogue Response Generation<br> Evaluating Open-Domain Dialogues in Latent Space with Next Sentence Prediction and Mutual Information<br> DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data Augmentation in Multi-Turn Conversations<br> DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization<br> White-Box Multi-Objective Adversarial Attack on Dialogue Generation<br> Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking<br> Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues<br> MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via Moral Discussions<br> Injecting knowledge into language generation: a case study in auto-charting after-visit care instructions from medical dialogue<br> BREAK: Breaking the Dialogue State Tracking Barrier with Beam Search and Re-ranking<br> Learning to Generate Equitable Text in Dialogue from Biased Training Data<br> CORE: Cooperative Training of Retriever-Reranker for Effective Dialogue Response Selection<br> PVGRU: Generating Diverse and Relevant Dialogue Responses via Pseudo-Variational Mechanism<br> DAMP: Doubly Aligned Multilingual Parser for Task-Oriented Dialogue<br> Knowledge-enhanced Mixed-initiative Dialogue System for Emotional Support Conversations<br> ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems<br> Towards Faithful Dialogues via Focus Learning<br> Prompter: Zero-shot Adaptive Prefixes for Dialogue State Tracking Domain Adaptation<br> Enhancing Dialogue Generation via Dynamic Graph Knowledge Aggregation<br> VSTAR: A Video-grounded Dialogue Dataset for Situated Semantic Understanding with Scene and Topic Transitions<br> Enhancing Personalized Dialogue Generation with Contrastive Latent Variables: Combining Sparse and Dense Persona<br> SIMMC-VR: A Task-oriented Multimodal Dialog Dataset with Situated and Immersive VR Streams<br> FutureTOD: Teaching Future Knowledge to Pre-trained Language Model for Task-Oriented Dialogue<br> Retrieval-free Knowledge Injection through Multi-Document Traversal for Dialogue Models<br> Annotating and Detecting Fine-grained Factual Errors for Dialogue Summarization<br> MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal Open-domain Conversation<br> Envisioning Future from the Past: Hierarchical Duality Learning for Multi-Turn Dialogue Generation<br> Using Domain Knowledge to Guide Dialog Structure Induction via Neural Probabilistic Soft Logic<br> A Dataset of Argumentative Dialogues on Scientific Papers<br> Contextual Knowledge Learning for Dialogue Generation<br> Speech-Text Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment<br> MidMed: Towards Mixed-Type Dialogues for Medical Consultation<br> RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized Dialogue Response Generation<br> Modeling User Satisfaction Dynamics in Dialogue via Hawkes Process<br> Pre-training Multi-party Dialogue Models with Latent Discourse Inference<br> PAED: Zero-Shot Persona Attribute Extraction in Dialogues<br> SimOAP: Improve Coherence and Consistency in Persona-based Dialogue Generation via Over-sampling and Post-evaluation<br> Dialog-Post: Multi-Level Self-Supervised Objectives and Hierarchical Model for Dialogue Post-Training<br> A Cognitive Stimulation Dialogue System with Multi-source Knowledge Fusion for Elders with Cognitive Impairment<br> A Synthetic Data Generation Framework for Grounded Dialogues<br> Multi-Grained Knowledge Retrieval for End-to-End Task-Oriented Dialog<br> XDailyDialog: A Multilingual Parallel Dialogue Corpus<br> RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue<br> PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and Compositional Experts<br> Learning New Skills after Deployment: Improving open-domain internet-driven dialogue with human feedback<br> On the Compositional Generalization in Versatile Open-domain Dialogue<br> Dialogue Summarization with Static-Dynamic Structure Fusion Graph<br> Reference Matters: Benchmarking Factual Error Correction for Dialogue Summarization with Fine-grained Evaluation Framework<br> Multimodal Persona Based Generation of Comic Dialogs<br> Seen to Unseen: Exploring Compositional Generalization of Multi-Attribute Controllable Dialogue Generation<br> Towards Understanding Omission in Dialogue Summarization<br> Don&#39;t Forget Your ABC&#39;s: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems<br> LiveChat: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming</p><h3 id="_2022-acl" tabindex="-1"><a class="header-anchor" href="#_2022-acl" aria-hidden="true">#</a> 2022 ACL</h3><p>Learning-by-Narrating: Narrative Pre-Training for Zero-Shot Dialogue Comprehension<br> Mismatch between Multi-turn Dialogue and its Evaluation Metric in Dialogue State Tracking<br> Towards Fair Evaluation of Dialogue State Tracking by Flexible Incorporation of Turn-level Performances<br> UniGDD: A Unified Generative Framework for Goal-Oriented Document-Grounded Dialogue<br> Investigating person-specific errors in chat-oriented dialogue systems<br> Can Visual Dialogue Models Do Scorekeeping? Exploring How Dialogue Representations Incrementally Encode Shared Knowledge<br> [CASPI] Causal-aware Safe Policy Improvement for Task-oriented Dialogue<br> UniTranSeR: A Unified Transformer Semantic Representation Framework for Multimodal Task-Oriented Dialog System<br> Dynamic Schema Graph Fusion Network for Multi-Domain Dialogue State Tracking<br> Structural Characterization for Dialogue Disentanglement<br> Multi-Party Empathetic Dialogue Generation: A New Task for Dialog Systems<br> DEAM: Dialogue Coherence Evaluation using AMR-based Semantic Manipulations<br> ProphetChat: Enhancing Dialogue Generation with Simulation of Future Conversation<br> Where to Go for the Holidays: Towards Mixed-Type Dialogs for Clarification of User Goals<br> Continual Prompt Tuning for Dialog State Tracking<br> Online Semantic Parsing for Latency Reduction in Task-Oriented Dialogue<br> Summ<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mi>N</mi></msup></mrow><annotation encoding="application/x-tex">^N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span></span></span></span></span></span></span>: A Multi-Stage Summarization Framework for Long Input Dialogues and Documents<br> GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems<br> Beyond the Granularity: Multi-Perspective Dialogue Collaborative Selection for Dialogue State Tracking<br> Other Roles Matter! Enhancing Role-Oriented Dialogue Summarization via Role Interactions<br> Multimodal Dialogue Response Generation<br> A Taxonomy of Empathetic Questions in Social Dialogs<br> Knowledge Enhanced Reflection Generation for Counseling Dialogues<br> Improving Multi-label Malevolence Detection in Dialogues through Multi-faceted Label Correlation Enhancement<br> The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems<br> DialFact: A Benchmark for Fact-Checking in Dialogue<br> There Are a Thousand Hamlets in a Thousand People&#39;s Eyes: Enhancing Knowledge-grounded Dialogue with Personal Memory<br> Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System<br> DialogVED: A Pre-trained Latent Variable Encoder-Decoder Model for Dialog Response Generation<br> An Interpretable Neuro-Symbolic Reasoning Framework for Task-Oriented Dialogue Generation<br> CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues<br> M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database<br> What does the sea say to the shore? A BERT based DST style approach for speaker to dialogue attribution in novels<br> When did you become so smart, oh wise one?! Sarcasm Explanation in Multi-modal Multi-party Dialogues<br> SalesBot: Transitioning from Chit-Chat to Task-Oriented Dialogues<br> Achieving Reliable Human Assessment of Open-Domain Dialogue Systems<br> SaFeRDialogues: Taking Feedback Gracefully after Conversational Safety Failures<br> The AI Doctor Is In: A Survey of Task-Oriented Dialogue Systems for Healthcare Applications<br> Lexical Knowledge Internalization for Neural Dialog Generation<br> A Model-agnostic Data Manipulation Method for Persona-based Dialogue Generation<br> Situated Dialogue Learning through Procedural Environment Generation<br> Internet-Augmented Dialogue Generation</p><h3 id="_2021-acl" tabindex="-1"><a class="header-anchor" href="#_2021-acl" aria-hidden="true">#</a> 2021 ACL</h3><p>Saying No is An Art: Contextualized Fallback Responses for Unanswerable Dialogue Queries<br> PRAL: A Tailored Pre-Training Model for Task-Oriented Dialog Generation<br> Continual Learning for Task-oriented Dialogue System with Iterative Network Pruning, Expanding and Masking<br> Unsupervised Enrichment of Persona-grounded Dialog with Background Stories<br> Domain-Adaptive Pretraining Methods for Dialogue Understanding<br> Preview, Attend and Review: Schema-Aware Curriculum Learning for Multi-Domain Dialogue State Tracking<br> On the Generation of Medical Dialogs for COVID-19<br> Constructing Multi-Modal Dialogue Dataset by Replacing Text with Semantically Relevant Images<br> Conversations Are Not Flat: Modeling the Dynamic Information Flow across Dialogue Utterances<br> Dual Slot Selector via Local Reliability Verification for Dialogue State Tracking<br> Transferable Dialogue Systems and User Simulators<br> BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data<br> SocAoG: Incremental Graph Parsing for Social Relation Inference in Dialogues<br> TicketTalk: Toward human-level performance with end-to-end, transaction-based dialog systems<br> Improving Dialog Systems for Negotiation with Personality Modeling<br> Learning from Perturbations: Diverse and Informative Dialogue Generation with Inverse Adversarial Training<br> Increasing Faithfulness in Knowledge-Grounded Dialogue with Controllable Features<br> Prosodic segmentation for parsing spoken dialogue<br> Language Model as an Annotator: Exploring DialoGPT for Dialogue Summarization<br> Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection<br> I like fish, especially dolphins: Addressing Contradictions in Dialogue Modeling<br> Discovering Dialog Structure Graph for Coherent Dialog Generation<br> A Sequence-to-Sequence Approach to Dialogue State Tracking<br> Dialogue Response Selection with Hierarchical Curriculum Learning<br> Discovering Dialogue Slots with Weak Supervision<br> Robustness Testing of Language Understanding in Task-Oriented Dialog<br> Comprehensive Study: How the Context Information of Different Granularity Affects Dialogue State Tracking?<br> OTTers: One-turn Topic Transitions for Open-Domain Dialogue<br> Towards Quantifiable Dialogue Coherence Evaluation<br> Novel Slot Detection: A Benchmark for Discovering Unknown Slot Types in the Task-Oriented Dialogue System<br> Towards Emotional Support Dialog Systems<br> Diversifying Dialog Generation via Adaptive Label Smoothing<br> NeuralWOZ: Learning to Collect Task-Oriented Dialogue via Model-Based Simulation<br> RADDLE: An Evaluation Benchmark and Analysis Platform for Robust Task-oriented Dialog Systems<br> Semantic Representation for Dialogue Modeling<br> Structural Pre-training for Dialogue Comprehension<br> A Human-machine Collaborative Framework for Evaluating Malevolence in Dialogues<br> Generating Relevant and Coherent Dialogue Responses using Self-Separated Conditional Variational AutoEncoders<br> DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded Dialogue<br> DynaEval: Unifying Turn and Dialogue Level Evaluation<br> RepSum: Unsupervised Dialogue Summarization based on Replacement Strategy<br> PhotoChat: A Human-Human Dialogue Dataset With Photo Sharing Behavior For Joint Image-Text Modeling<br> Space Efficient Context Encoding for Non-Task-Oriented Dialogue Generation with Graph Attention Transformer<br> DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations<br> TIMEDIAL: Temporal Commonsense Reasoning in Dialog</p><h3 id="_2020-acl" tabindex="-1"><a class="header-anchor" href="#_2020-acl" aria-hidden="true">#</a> 2020 ACL</h3><p>ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and Diagnosing Dialogue Systems<br> DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation<br> Conversation Learner - A Machine Teaching Tool for Building Dialog Managers for Task-Oriented Dialog Systems<br> Designing Precise and Robust Dialogue Response Evaluators<br> Dialogue State Tracking with Explicit Slot Connection Modeling<br> Large Scale Multi-Actor Generative Dialog Modeling<br> PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable<br> Slot-consistent NLG for Task-oriented Dialogue Systems with Iterative Rectification Network<br> Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained Conversational Representations<br> Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking<br> Efficient Dialogue State Tracking by Selectively Overwriting Memory<br> End-to-End Neural Pipeline for Goal-Oriented Dialogue Systems using GPT-2<br> Evaluating Dialogue Generation Systems via Response Selection<br> Learning Low-Resource End-To-End Goal-Oriented Dialog for Fast and Reliable System Deployment<br> Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward Decomposition<br> Paraphrase Augmented Task-Oriented Dialog Generation<br> Semi-Supervised Dialogue Policy Learning via Stochastic Reward Estimation<br> USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation<br> Towards Conversational Recommendation over Multi-Type Dialogs<br> Crawling and Preprocessing Mailing Lists At Scale for Dialog Analysis<br> Beyond User Self-Reported Likert Scale Ratings: A Comparison Model for Automatic Dialog Evaluation<br> Conversational Word Embedding for Retrieval-Based Dialog System<br> Learning Dialog Policies from Weak Demonstrations<br> MuTual: A Dataset for Multi-Turn Dialogue Reasoning<br> You Impress Me: Dialogue Generation via Mutual Persona Perception<br> Dialogue Coherence Assessment Without Explicit Dialogue Act Labels<br> &quot;None of the Above&quot;: Measure Uncertainty in Dialog Response Retrieval<br> Negative Training for Neural Dialogue Response Generation<br> Recursive Template-based Frame Generation for Task Oriented Dialog<br> Grounding Conversations with Improvised Dialogues<br> Learning an Unreferenced Metric for Online Dialogue Evaluation<br> Neural Generation of Dialogue Response Timings<br> The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents<br> Learning to execute instructions in a Minecraft dialogue<br> ChartDialogs: Plotting from Natural Language Instructions<br> Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation<br> Towards Emotion-aided Multi-modal Dialogue Act Classification<br> Don&#39;t Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood Training<br> Dialogue-Based Relation Extraction<br> More Diverse Dialogue Datasets via Diversity-Informed Data Collection<br> Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset<br> Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for Span-based Question Answering<br> Diverse and Informative Dialogue Generation with Context-Specific Commonsense Knowledge Awareness<br> Generate, Delete and Rewrite: A Three-Stage Framework for Improving Persona Consistency of Dialogue Generation<br> Learning to Customize Model Structures for Few-shot Dialogue Generation Tasks<br> Video-Grounded Dialogues with Pretrained Generation Language Models<br> A Contextual Hierarchical Attention Network with Adaptive Objective for Dialogue State Tracking<br> Data Manipulation: Towards Effective Instance Learning for Neural Dialogue Generation via Learning to Augment and Reweight<br> Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog<br> Learning Efficient Dialogue Policy from Demonstrations through Shaping<br> SAS: Dialogue State Tracking via Slot Attention and Slot Information Sharing<br> MIE: A Medical Information Extractor towards Medical Dialogues<br> Diversifying Dialogue Generation with Non-Conversational Text<br> KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation<br> Meta-Reinforced Multi-Domain State Generator for Dialogue Systems<br> Modeling Long Context for Task-Oriented Dialogue State Generation<br> Multi-Domain Dialogue Acts and Response Co-Generation<br> History for Visual Dialog: Do we really need it?</p><h3 id="_2019-acl" tabindex="-1"><a class="header-anchor" href="#_2019-acl" aria-hidden="true">#</a> 2019 ACL</h3><p>Dialogue-Act Prediction of Future Responses Based on Conversation History<br> One Time of Interaction May Not Be Enough: Go Deep with an Interaction-over-Interaction Network for Response Selection in Dialogues<br> Improving Multi-turn Dialogue Modelling with Utterance ReWriter<br> Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study<br> Boosting Dialog Response Generation<br> Implicit Discourse Relation Identification for Open-domain Dialogues<br> Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems<br> Constrained Decoding for Neural NLG from Compositional Representations in Task-Oriented Dialogue<br> Domain Adaptive Dialog Generation via Meta Learning<br> The PhotoBook Dataset: Building Common Ground through Visually-Grounded Dialogue<br> Learning from Dialogue after Deployment: Feed Yourself, Chatbot!<br> A Working Memory Model for Task-oriented Dialog Response Generation<br> Generating Responses with a Specific Emotion in Dialog<br> Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention<br> ReCoSa: Detecting the Relevant Contexts with Self-Attention for Multi-turn Dialogue Generation<br> Incremental Learning from Scratch for Task-Oriented Dialogue Systems<br> Dialogue Natural Language Inference<br> Budgeted Policy Learning for Task-Oriented Dialogue Systems<br> Learning a Matching Model with Co-teaching for Multi-turn Response Selection in Retrieval-based Dialogue Systems<br> Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References<br> Pretraining Methods for Dialog Context Representation Learning<br> Self-Supervised Dialogue Learning<br> Know More about Each Other: Evolving Dialogue Strategy via Compound Assessment<br> Training Neural Response Selection for Task-Oriented Dialogue Systems<br> Collaborative Dialogue in Minecraft<br> Ordinal and Attribute Aware Response Generation in a Multimodal Dialogue System<br> Memory Consolidation for Contextual Spoken Language Understanding with Dialogue Logistic Inference<br> Personalizing Dialogue Agents via Meta-Learning<br> Reading Turn by Turn: Hierarchical Attention Architecture for Spoken Dialogue Comprehension<br> Rationally Reappraising ATIS-based Dialogue Systems<br> Observing Dialogue in Therapy: Categorizing and Forecasting Behavioral Codes<br> Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems<br> Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good<br> What Should I Ask? Using Conversationally Informative Rewards for Goal-oriented Visual Dialog<br> Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog</p></div><!----><footer class="page-meta"><!----><div class="meta-item git-info"><div class="update-time"><span class="label">ä¸Šæ¬¡ç¼–è¾‘äº: </span><!----></div><div class="contributors"><span class="label">è´¡çŒ®è€…: </span><!--[--><!--[--><span class="contributor" title="email: 799976781@qq.com">WillebrordSnell</span><!--]--><!--]--></div></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">è¥¿æ¹–ç¾æ™¯, ä¸‰æœˆå¤©å˜~</div><div class="vp-copyright">Copyright Â© 2023 Mr.R</div></footer></div><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-b95f5b1a.js" defer></script>
  </body>
</html>
